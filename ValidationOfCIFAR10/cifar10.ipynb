{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Validating the effectiveness of Opacus-DPCR\n",
    "To verify the effectiveness of Opacus-DPCR, the script uses CIFAR10 as the experimental dataset. Since the current version of Opacus-DPCR was developed based on Opacus 1.1.2, we used the following official example to conduct our experiments:\n",
    "\n",
    "[https://github.com/pytorch/opacus/blob/v1.1.2/examples/cifar10.py](https://github.com/pytorch/opacus/blob/v1.1.2/examples/cifar10.py)\n",
    "\n",
    "To ensure the credibility of the experiment, we maintained all other parameters constant and only varied the value of sigma.\n",
    "In the following experiments, sigma is set to **4.18**, which allowed the trained model to achieve **(2, 1e-5)-Differential Privacy** under the default parameters.\n",
    "\n",
    "The selectable models (**dpcr_model**) include NoDPCR (without DPCR, using Opacus directly), SimpleMech, TwoLevel, BinMech, FDA, BCRG, and ABCRG."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Setup Instructions of This Jupyter Script\n",
    "\n",
    "1. Install Jupyter\n",
    "```bash\n",
    "pip install jupyter\n",
    "```\n",
    "\n",
    "2. Install PyTorch with CUDA (if you have GPU)\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "\n",
    "3. Install Opacus-DPCR for Differential Privacy\n",
    "```bash\n",
    "pip install opacus-dpcr==0.1.2\n",
    "```\n",
    "\n",
    "Run `jupyter notebook` to start using the Jupyter script.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# load python script for experiments\n",
    "from cifar10_dpcr import main\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(1) We test the learning effectiveness for traditional Differentially Private learning, i.e., using Opacus directly.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **traditional differential privacy learning** achieves:\n",
    "Accuracy of **35.2%** and Loss of **2.00** after private training.\n",
    "Best Accuracy of **44.5%** and best Loss of **1.84** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "You select traditional DP learning...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.303038 Acc@1: 0.102443 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.278000 Acc@1: 0.123903 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.084533 Acc@1: 0.238379 \n",
      "\tTrain Epoch: 2 \tLoss: 2.120832 Acc@1: 0.243518 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.187972 Acc@1: 0.239640 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.109017 Acc@1: 0.258447 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.010011 Acc@1: 0.316895 \n",
      "\tTrain Epoch: 3 \tLoss: 2.015911 Acc@1: 0.298462 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.918372 Acc@1: 0.333842 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.891330 Acc@1: 0.347411 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 2.319391 Acc@1: 0.320605 \n",
      "\tTrain Epoch: 4 \tLoss: 2.375123 Acc@1: 0.304757 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.076312 Acc@1: 0.339379 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.964199 Acc@1: 0.354276 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.840798 Acc@1: 0.391504 \n",
      "\tTrain Epoch: 5 \tLoss: 1.847373 Acc@1: 0.392386 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.851263 Acc@1: 0.408976 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.859047 Acc@1: 0.413628 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.866653 Acc@1: 0.410352 \n",
      "\tTrain Epoch: 6 \tLoss: 1.907267 Acc@1: 0.415591 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.930056 Acc@1: 0.410157 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.931618 Acc@1: 0.414984 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.926653 Acc@1: 0.422559 \n",
      "\tTrain Epoch: 7 \tLoss: 1.905773 Acc@1: 0.416968 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.955177 Acc@1: 0.420063 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 2.001187 Acc@1: 0.415415 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 2.142238 Acc@1: 0.386426 \n",
      "\tTrain Epoch: 8 \tLoss: 2.094001 Acc@1: 0.400200 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.972506 Acc@1: 0.420407 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.965486 Acc@1: 0.423913 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 1.967954 Acc@1: 0.430469 \n",
      "\tTrain Epoch: 9 \tLoss: 1.899394 Acc@1: 0.446509 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.929214 Acc@1: 0.436524 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.946276 Acc@1: 0.438668 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.936299 Acc@1: 0.445215 \n",
      "\tTrain Epoch: 10 \tLoss: 1.975995 Acc@1: 0.427651 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.052046 Acc@1: 0.427941 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.089450 Acc@1: 0.426765 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 2.053017 Acc@1: 0.415820 \n",
      "\tTrain Epoch: 11 \tLoss: 1.999247 Acc@1: 0.435540 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.150705 Acc@1: 0.416858 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.157238 Acc@1: 0.419753 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 2.252839 Acc@1: 0.419141 \n",
      "\tTrain Epoch: 12 \tLoss: 2.267164 Acc@1: 0.424404 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.221933 Acc@1: 0.433301 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.192401 Acc@1: 0.436121 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 2.195023 Acc@1: 0.439551 \n",
      "\tTrain Epoch: 13 \tLoss: 2.074552 Acc@1: 0.464214 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.185915 Acc@1: 0.436791 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.208230 Acc@1: 0.432565 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.214221 Acc@1: 0.429297 \n",
      "\tTrain Epoch: 14 \tLoss: 2.101415 Acc@1: 0.447732 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.191212 Acc@1: 0.439578 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.209524 Acc@1: 0.432832 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.242397 Acc@1: 0.426465 \n",
      "\tTrain Epoch: 15 \tLoss: 2.194709 Acc@1: 0.434151 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.144764 Acc@1: 0.430788 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.162853 Acc@1: 0.431553 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 2.268659 Acc@1: 0.415039 \n",
      "\tTrain Epoch: 16 \tLoss: 2.194122 Acc@1: 0.450611 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.196960 Acc@1: 0.424265 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.207202 Acc@1: 0.426000 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.148616 Acc@1: 0.427148 \n",
      "\tTrain Epoch: 17 \tLoss: 2.216563 Acc@1: 0.404103 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.183893 Acc@1: 0.430187 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.199012 Acc@1: 0.435334 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.256324 Acc@1: 0.429102 \n",
      "\tTrain Epoch: 18 \tLoss: 2.245894 Acc@1: 0.453858 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.222210 Acc@1: 0.439579 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.227127 Acc@1: 0.437435 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.227918 Acc@1: 0.413281 \n",
      "\tTrain Epoch: 19 \tLoss: 2.211294 Acc@1: 0.410932 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.224947 Acc@1: 0.426038 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.281105 Acc@1: 0.420975 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.495740 Acc@1: 0.412500 \n",
      "\tTrain Epoch: 20 \tLoss: 2.491787 Acc@1: 0.429477 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 2.395306 Acc@1: 0.412001 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 2.390824 Acc@1: 0.411321 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.336638 Acc@1: 0.418652 \n",
      "\tTrain Epoch: 21 \tLoss: 2.238132 Acc@1: 0.431102 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 2.308388 Acc@1: 0.412593 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 2.312072 Acc@1: 0.414165 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.332314 Acc@1: 0.416211 \n",
      "\tTrain Epoch: 22 \tLoss: 2.502912 Acc@1: 0.394750 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.251143 Acc@1: 0.418256 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.254912 Acc@1: 0.416400 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.284582 Acc@1: 0.410059 \n",
      "\tTrain Epoch: 23 \tLoss: 2.260479 Acc@1: 0.422439 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.324639 Acc@1: 0.411547 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.322853 Acc@1: 0.410077 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.280495 Acc@1: 0.395996 \n",
      "\tTrain Epoch: 24 \tLoss: 2.202069 Acc@1: 0.402370 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.363235 Acc@1: 0.401971 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.350598 Acc@1: 0.405270 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.177047 Acc@1: 0.398047 \n",
      "\tTrain Epoch: 25 \tLoss: 2.198455 Acc@1: 0.407734 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.277835 Acc@1: 0.411080 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.278474 Acc@1: 0.414485 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.338681 Acc@1: 0.410352 \n",
      "\tTrain Epoch: 26 \tLoss: 2.298773 Acc@1: 0.414564 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.251047 Acc@1: 0.419160 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.298932 Acc@1: 0.418813 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.361845 Acc@1: 0.410059 \n",
      "\tTrain Epoch: 27 \tLoss: 2.518116 Acc@1: 0.410980 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.287106 Acc@1: 0.415117 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.296490 Acc@1: 0.414444 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.307493 Acc@1: 0.396777 \n",
      "\tTrain Epoch: 28 \tLoss: 2.321165 Acc@1: 0.408194 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 2.288334 Acc@1: 0.408513 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 2.309991 Acc@1: 0.412198 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.327728 Acc@1: 0.407031 \n",
      "\tTrain Epoch: 29 \tLoss: 2.391641 Acc@1: 0.403483 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 2.274137 Acc@1: 0.408011 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 2.237115 Acc@1: 0.408095 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.240776 Acc@1: 0.393848 \n",
      "\tTrain Epoch: 30 \tLoss: 2.179075 Acc@1: 0.404895 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 2.160157 Acc@1: 0.408390 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 2.173533 Acc@1: 0.414890 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.314166 Acc@1: 0.398340 \n",
      "\tTrain Epoch: 31 \tLoss: 2.259170 Acc@1: 0.413655 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 2.249509 Acc@1: 0.405586 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 2.213718 Acc@1: 0.406911 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.232441 Acc@1: 0.395020 \n",
      "\tTrain Epoch: 32 \tLoss: 2.244096 Acc@1: 0.392715 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 2.246432 Acc@1: 0.402313 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 2.240913 Acc@1: 0.405223 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.282943 Acc@1: 0.400977 \n",
      "\tTrain Epoch: 33 \tLoss: 2.173489 Acc@1: 0.425389 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 2.242354 Acc@1: 0.399593 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 2.260148 Acc@1: 0.399745 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.391525 Acc@1: 0.395410 \n",
      "\tTrain Epoch: 34 \tLoss: 2.353573 Acc@1: 0.411337 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 2.157143 Acc@1: 0.401303 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 2.184908 Acc@1: 0.394266 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.333867 Acc@1: 0.366016 \n",
      "\tTrain Epoch: 35 \tLoss: 2.315606 Acc@1: 0.382166 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 2.331610 Acc@1: 0.390906 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 2.290308 Acc@1: 0.396293 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.240487 Acc@1: 0.395605 \n",
      "\tTrain Epoch: 36 \tLoss: 2.208886 Acc@1: 0.391326 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 2.218927 Acc@1: 0.386139 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 2.194449 Acc@1: 0.391976 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.098701 Acc@1: 0.394531 \n",
      "\tTrain Epoch: 37 \tLoss: 2.141078 Acc@1: 0.389662 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 2.172816 Acc@1: 0.399906 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 2.168363 Acc@1: 0.405839 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.224348 Acc@1: 0.406934 \n",
      "\tTrain Epoch: 38 \tLoss: 2.201009 Acc@1: 0.402681 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 2.252254 Acc@1: 0.404065 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 2.215258 Acc@1: 0.400640 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.359895 Acc@1: 0.401953 \n",
      "\tTrain Epoch: 39 \tLoss: 2.343426 Acc@1: 0.392806 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 2.189471 Acc@1: 0.397904 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 2.180736 Acc@1: 0.394509 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.144943 Acc@1: 0.384082 \n",
      "\tTrain Epoch: 40 \tLoss: 2.124474 Acc@1: 0.391003 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 2.172640 Acc@1: 0.387154 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 2.145119 Acc@1: 0.391568 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.106187 Acc@1: 0.394824 \n",
      "\tTrain Epoch: 41 \tLoss: 2.048019 Acc@1: 0.389940 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 2.107937 Acc@1: 0.398976 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 2.134498 Acc@1: 0.399851 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.269631 Acc@1: 0.370996 \n",
      "\tTrain Epoch: 42 \tLoss: 2.291703 Acc@1: 0.374637 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 2.254275 Acc@1: 0.392185 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 2.226892 Acc@1: 0.387648 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.072935 Acc@1: 0.370312 \n",
      "\tTrain Epoch: 43 \tLoss: 2.026632 Acc@1: 0.381715 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.140139 Acc@1: 0.396738 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.150059 Acc@1: 0.396379 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.139765 Acc@1: 0.392969 \n",
      "\tTrain Epoch: 44 \tLoss: 2.117053 Acc@1: 0.381398 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 2.149474 Acc@1: 0.396282 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 2.197894 Acc@1: 0.371478 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.088967 Acc@1: 0.375488 \n",
      "\tTrain Epoch: 45 \tLoss: 2.003976 Acc@1: 0.382550 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 2.192789 Acc@1: 0.382424 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 2.155106 Acc@1: 0.381651 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.060879 Acc@1: 0.383008 \n",
      "\tTrain Epoch: 46 \tLoss: 2.048169 Acc@1: 0.393052 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 2.079681 Acc@1: 0.388849 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 2.109014 Acc@1: 0.382755 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.092572 Acc@1: 0.385449 \n",
      "\tTrain Epoch: 47 \tLoss: 2.156557 Acc@1: 0.371978 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 2.073312 Acc@1: 0.394917 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 2.083047 Acc@1: 0.388739 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.127310 Acc@1: 0.383105 \n",
      "\tTrain Epoch: 48 \tLoss: 2.072953 Acc@1: 0.402282 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 2.164594 Acc@1: 0.384346 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 2.178541 Acc@1: 0.385860 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.189096 Acc@1: 0.351074 \n",
      "\tTrain Epoch: 49 \tLoss: 2.211787 Acc@1: 0.336114 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 2.155314 Acc@1: 0.375991 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 2.160614 Acc@1: 0.378055 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.054819 Acc@1: 0.380957 \n",
      "\tTrain Epoch: 50 \tLoss: 2.063912 Acc@1: 0.384988 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 2.068092 Acc@1: 0.387615 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 2.089391 Acc@1: 0.386573 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.166560 Acc@1: 0.370801 \n",
      "\tTrain Epoch: 51 \tLoss: 2.226911 Acc@1: 0.352796 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 2.159396 Acc@1: 0.380752 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 2.126645 Acc@1: 0.382400 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.245124 Acc@1: 0.382422 \n",
      "\tTrain Epoch: 52 \tLoss: 2.216830 Acc@1: 0.377434 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 2.138770 Acc@1: 0.393905 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 2.132946 Acc@1: 0.393269 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.131366 Acc@1: 0.379590 \n",
      "\tTrain Epoch: 53 \tLoss: 1.994487 Acc@1: 0.393350 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 2.096778 Acc@1: 0.402379 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 2.082320 Acc@1: 0.402745 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.107482 Acc@1: 0.388281 \n",
      "\tTrain Epoch: 54 \tLoss: 2.113121 Acc@1: 0.396199 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 2.083585 Acc@1: 0.393064 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 2.070860 Acc@1: 0.394866 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.229032 Acc@1: 0.380176 \n",
      "\tTrain Epoch: 55 \tLoss: 2.070538 Acc@1: 0.404595 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 2.127860 Acc@1: 0.394448 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 2.130078 Acc@1: 0.396659 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.132523 Acc@1: 0.387109 \n",
      "\tTrain Epoch: 56 \tLoss: 2.036701 Acc@1: 0.396670 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 2.086723 Acc@1: 0.401094 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 2.114833 Acc@1: 0.399305 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.158673 Acc@1: 0.367773 \n",
      "\tTrain Epoch: 57 \tLoss: 2.108153 Acc@1: 0.386364 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 2.207779 Acc@1: 0.394341 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 2.213250 Acc@1: 0.393662 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.080105 Acc@1: 0.378711 \n",
      "\tTrain Epoch: 58 \tLoss: 2.058255 Acc@1: 0.403112 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 2.124428 Acc@1: 0.389454 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 2.140443 Acc@1: 0.388364 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.158137 Acc@1: 0.392773 \n",
      "\tTrain Epoch: 59 \tLoss: 2.167727 Acc@1: 0.393180 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 2.136520 Acc@1: 0.400902 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 2.137283 Acc@1: 0.399291 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.073408 Acc@1: 0.365234 \n",
      "\tTrain Epoch: 60 \tLoss: 2.025028 Acc@1: 0.375449 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 2.079022 Acc@1: 0.390610 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 2.095138 Acc@1: 0.387095 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.092227 Acc@1: 0.353223 \n",
      "\tTrain Epoch: 61 \tLoss: 2.034627 Acc@1: 0.355381 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 2.123274 Acc@1: 0.385820 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 2.115590 Acc@1: 0.385807 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.079655 Acc@1: 0.375684 \n",
      "\tTrain Epoch: 62 \tLoss: 2.051137 Acc@1: 0.368882 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 2.149146 Acc@1: 0.381139 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 2.150536 Acc@1: 0.373020 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.333471 Acc@1: 0.377051 \n",
      "\tTrain Epoch: 63 \tLoss: 2.434155 Acc@1: 0.367845 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 2.168907 Acc@1: 0.378858 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 2.180799 Acc@1: 0.383810 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.172699 Acc@1: 0.387793 \n",
      "\tTrain Epoch: 64 \tLoss: 2.187166 Acc@1: 0.378311 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 2.133324 Acc@1: 0.382876 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 2.138164 Acc@1: 0.383805 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.208491 Acc@1: 0.394336 \n",
      "\tTrain Epoch: 65 \tLoss: 2.249543 Acc@1: 0.385406 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 2.105739 Acc@1: 0.391373 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 2.124476 Acc@1: 0.387805 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.292298 Acc@1: 0.352637 \n",
      "\tTrain Epoch: 66 \tLoss: 2.293440 Acc@1: 0.353623 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 2.143976 Acc@1: 0.368706 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 2.122270 Acc@1: 0.371103 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.349856 Acc@1: 0.373730 \n",
      "\tTrain Epoch: 67 \tLoss: 2.342998 Acc@1: 0.376663 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 2.178970 Acc@1: 0.371965 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 2.149760 Acc@1: 0.370732 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.065543 Acc@1: 0.348438 \n",
      "\tTrain Epoch: 68 \tLoss: 2.057673 Acc@1: 0.359539 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 2.131851 Acc@1: 0.372068 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 2.140743 Acc@1: 0.368970 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.210364 Acc@1: 0.362305 \n",
      "\tTrain Epoch: 69 \tLoss: 2.205836 Acc@1: 0.385385 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 2.154686 Acc@1: 0.372869 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 2.167240 Acc@1: 0.372975 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.119182 Acc@1: 0.358496 \n",
      "\tTrain Epoch: 70 \tLoss: 2.174161 Acc@1: 0.341512 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 2.222717 Acc@1: 0.357366 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 2.226393 Acc@1: 0.359923 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.146166 Acc@1: 0.347461 \n",
      "\tTrain Epoch: 71 \tLoss: 2.124961 Acc@1: 0.357213 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 2.258759 Acc@1: 0.366844 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 2.250571 Acc@1: 0.370737 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.224748 Acc@1: 0.377832 \n",
      "\tTrain Epoch: 72 \tLoss: 2.303278 Acc@1: 0.378270 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 2.199340 Acc@1: 0.381891 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 2.214983 Acc@1: 0.381146 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.331199 Acc@1: 0.351758 \n",
      "\tTrain Epoch: 73 \tLoss: 2.322310 Acc@1: 0.377925 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 2.247225 Acc@1: 0.375704 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 2.259650 Acc@1: 0.369758 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.148896 Acc@1: 0.370605 \n",
      "\tTrain Epoch: 74 \tLoss: 2.076152 Acc@1: 0.390173 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 2.201574 Acc@1: 0.370091 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 2.160207 Acc@1: 0.371146 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.053388 Acc@1: 0.356641 \n",
      "\tTrain Epoch: 75 \tLoss: 2.006335 Acc@1: 0.376849 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 2.140388 Acc@1: 0.374363 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 2.145930 Acc@1: 0.373329 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.091649 Acc@1: 0.351270 \n",
      "\tTrain Epoch: 76 \tLoss: 2.018621 Acc@1: 0.386500 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 2.174115 Acc@1: 0.373982 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 2.158455 Acc@1: 0.375199 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.059356 Acc@1: 0.374023 \n",
      "\tTrain Epoch: 77 \tLoss: 2.167865 Acc@1: 0.370107 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 2.118466 Acc@1: 0.380095 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 2.124425 Acc@1: 0.380342 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 2.038262 Acc@1: 0.368848 \n",
      "\tTrain Epoch: 78 \tLoss: 2.032128 Acc@1: 0.370244 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 2.112409 Acc@1: 0.379983 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 2.128267 Acc@1: 0.374583 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 2.068612 Acc@1: 0.354297 \n",
      "\tTrain Epoch: 79 \tLoss: 2.128061 Acc@1: 0.368550 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 2.125940 Acc@1: 0.363043 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 2.141625 Acc@1: 0.363937 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 2.069788 Acc@1: 0.369531 \n",
      "\tTrain Epoch: 80 \tLoss: 2.141234 Acc@1: 0.361000 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 2.166720 Acc@1: 0.370089 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 2.141354 Acc@1: 0.366486 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 2.079859 Acc@1: 0.355859 \n",
      "\tTrain Epoch: 81 \tLoss: 2.168079 Acc@1: 0.355681 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 2.099317 Acc@1: 0.363489 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 2.124049 Acc@1: 0.362250 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 2.181473 Acc@1: 0.355566 \n",
      "\tTrain Epoch: 82 \tLoss: 2.232171 Acc@1: 0.374938 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 2.132977 Acc@1: 0.371515 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 2.138694 Acc@1: 0.365952 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 2.149601 Acc@1: 0.350391 \n",
      "\tTrain Epoch: 83 \tLoss: 2.149834 Acc@1: 0.357072 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 2.118201 Acc@1: 0.365517 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 2.142663 Acc@1: 0.363556 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 2.058168 Acc@1: 0.350879 \n",
      "\tTrain Epoch: 84 \tLoss: 2.159633 Acc@1: 0.350025 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 2.127794 Acc@1: 0.365125 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 2.142118 Acc@1: 0.363759 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 2.198363 Acc@1: 0.374219 \n",
      "\tTrain Epoch: 85 \tLoss: 2.167647 Acc@1: 0.395960 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 2.107253 Acc@1: 0.365866 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 2.135297 Acc@1: 0.363455 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 2.102862 Acc@1: 0.356055 \n",
      "\tTrain Epoch: 86 \tLoss: 2.136219 Acc@1: 0.348049 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 2.123974 Acc@1: 0.371978 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 2.109555 Acc@1: 0.372256 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 2.248230 Acc@1: 0.357715 \n",
      "\tTrain Epoch: 87 \tLoss: 2.270137 Acc@1: 0.356608 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 2.136481 Acc@1: 0.364449 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 2.124808 Acc@1: 0.362490 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 2.144495 Acc@1: 0.366309 \n",
      "\tTrain Epoch: 88 \tLoss: 2.172739 Acc@1: 0.367328 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 2.144486 Acc@1: 0.361921 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 2.135054 Acc@1: 0.367908 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 2.203118 Acc@1: 0.370898 \n",
      "\tTrain Epoch: 89 \tLoss: 2.173601 Acc@1: 0.367211 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 2.124707 Acc@1: 0.367777 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 2.130770 Acc@1: 0.367385 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 2.534334 Acc@1: 0.374219 \n",
      "\tTrain Epoch: 90 \tLoss: 2.521590 Acc@1: 0.369077 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 2.170082 Acc@1: 0.367154 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 2.152673 Acc@1: 0.362737 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 20:23:43:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 20:23:43:INFO:{'accuracy': 0.44521484375, 'accuracy_per_epoch': [0.23837890625, 0.31689453125, 0.32060546875, 0.39150390625, 0.4103515625, 0.42255859375, 0.38642578125, 0.43046875, 0.44521484375, 0.4158203125, 0.419140625, 0.43955078125, 0.429296875, 0.42646484375, 0.4150390625, 0.4271484375, 0.4291015625, 0.41328125, 0.4125, 0.41865234375, 0.4162109375, 0.41005859375, 0.39599609375, 0.398046875, 0.4103515625, 0.41005859375, 0.39677734375, 0.40703125, 0.39384765625, 0.39833984375, 0.39501953125, 0.4009765625, 0.39541015625, 0.366015625, 0.39560546875, 0.39453125, 0.40693359375, 0.401953125, 0.38408203125, 0.39482421875, 0.37099609375, 0.3703125, 0.39296875, 0.37548828125, 0.3830078125, 0.38544921875, 0.38310546875, 0.35107421875, 0.38095703125, 0.37080078125, 0.382421875, 0.37958984375, 0.38828125, 0.38017578125, 0.387109375, 0.3677734375, 0.3787109375, 0.3927734375, 0.365234375, 0.35322265625, 0.37568359375, 0.37705078125, 0.38779296875, 0.3943359375, 0.35263671875, 0.37373046875, 0.3484375, 0.3623046875, 0.35849609375, 0.3474609375, 0.37783203125, 0.3517578125, 0.37060546875, 0.356640625, 0.35126953125, 0.3740234375, 0.36884765625, 0.354296875, 0.36953125, 0.355859375, 0.35556640625, 0.350390625, 0.35087890625, 0.37421875, 0.3560546875, 0.35771484375, 0.36630859375, 0.3708984375, 0.37421875, 0.35205078125], 'avg_time_per_epoch_str': '0:00:08', 'time_per_epoch': [11.976368, 9.141029, 8.865778, 8.915009, 8.980472, 8.903801, 8.805658, 8.906199, 8.915165, 8.986669, 9.072134, 8.999286, 9.009805, 9.008523, 8.979861, 8.925349, 8.97736, 9.008934, 8.947179, 8.952238, 8.96642, 8.908731, 8.886916, 8.845935, 8.916785, 8.911809, 8.871478, 8.692344, 8.833777, 8.901139, 8.839713, 8.874306, 8.854712, 8.758374, 8.918903, 8.782407, 8.789683, 8.873625, 8.928786, 8.828838, 8.830307, 8.940469, 8.881973, 8.950284, 8.784137, 8.980673, 8.905693, 8.977612, 8.920719, 8.931683, 8.939239, 9.010645, 8.947258, 8.941662, 8.778577, 8.92907, 8.956526, 8.81542, 8.868932, 8.830608, 8.824177, 8.737403, 8.924306, 8.835034, 8.780438, 8.99429, 8.83262, 8.818965, 8.772905, 8.790585, 8.86778, 8.8887, 8.84539, 8.964366, 9.101717, 9.291463, 9.211847, 9.475834, 9.240916, 8.986087, 9.052639, 9.017401, 9.063619, 8.965052, 8.969751, 8.976935, 8.975346, 9.022673, 8.953626, 8.938333]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 2.002195 Acc@1: 0.352051 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='NoDPCR',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2) We test the learning effectiveness for Private learning for Opacus-DPCR with **SimpleMech model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **SimpleMech** achieves:\n",
    "Accuracy of **36.1%** and Loss of **2.39** after private training.\n",
    "Best Accuracy of **44.2%** and best Loss of **1.83** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with SimpleMech...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.303038 Acc@1: 0.102443 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.278002 Acc@1: 0.123927 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.084503 Acc@1: 0.238477 \n",
      "\tTrain Epoch: 2 \tLoss: 2.120789 Acc@1: 0.244026 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.187935 Acc@1: 0.239643 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.108847 Acc@1: 0.258730 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.007676 Acc@1: 0.317285 \n",
      "\tTrain Epoch: 3 \tLoss: 2.013460 Acc@1: 0.301026 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.918116 Acc@1: 0.334077 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.890908 Acc@1: 0.347821 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 2.332027 Acc@1: 0.320312 \n",
      "\tTrain Epoch: 4 \tLoss: 2.386106 Acc@1: 0.303766 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.088043 Acc@1: 0.339012 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.971580 Acc@1: 0.353570 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.833353 Acc@1: 0.391406 \n",
      "\tTrain Epoch: 5 \tLoss: 1.838628 Acc@1: 0.395939 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.850766 Acc@1: 0.408981 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.859699 Acc@1: 0.412272 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.880756 Acc@1: 0.403320 \n",
      "\tTrain Epoch: 6 \tLoss: 1.930988 Acc@1: 0.412115 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.947011 Acc@1: 0.405465 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.947911 Acc@1: 0.409043 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.918721 Acc@1: 0.412305 \n",
      "\tTrain Epoch: 7 \tLoss: 1.920019 Acc@1: 0.412830 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.973781 Acc@1: 0.412567 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.974258 Acc@1: 0.413433 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 2.024333 Acc@1: 0.412891 \n",
      "\tTrain Epoch: 8 \tLoss: 1.961231 Acc@1: 0.426213 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.953605 Acc@1: 0.432567 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.956071 Acc@1: 0.431936 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 2.055536 Acc@1: 0.431152 \n",
      "\tTrain Epoch: 9 \tLoss: 1.967914 Acc@1: 0.453541 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.991968 Acc@1: 0.434310 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.971941 Acc@1: 0.436558 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.939720 Acc@1: 0.442480 \n",
      "\tTrain Epoch: 10 \tLoss: 1.993092 Acc@1: 0.421209 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.052001 Acc@1: 0.428031 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.069119 Acc@1: 0.429562 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 2.024534 Acc@1: 0.418262 \n",
      "\tTrain Epoch: 11 \tLoss: 1.971857 Acc@1: 0.442509 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.106981 Acc@1: 0.430324 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.205578 Acc@1: 0.418861 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 2.293823 Acc@1: 0.423730 \n",
      "\tTrain Epoch: 12 \tLoss: 2.353089 Acc@1: 0.429752 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.300538 Acc@1: 0.422456 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.229990 Acc@1: 0.426409 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 2.208333 Acc@1: 0.437402 \n",
      "\tTrain Epoch: 13 \tLoss: 2.097655 Acc@1: 0.450605 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.126864 Acc@1: 0.441099 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.150420 Acc@1: 0.436956 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.259204 Acc@1: 0.432422 \n",
      "\tTrain Epoch: 14 \tLoss: 2.121241 Acc@1: 0.450197 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.187359 Acc@1: 0.440999 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.205932 Acc@1: 0.436654 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.223772 Acc@1: 0.415820 \n",
      "\tTrain Epoch: 15 \tLoss: 2.140017 Acc@1: 0.425638 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.124565 Acc@1: 0.428598 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.148907 Acc@1: 0.431681 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 2.211246 Acc@1: 0.413184 \n",
      "\tTrain Epoch: 16 \tLoss: 2.071747 Acc@1: 0.449593 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.214811 Acc@1: 0.427667 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.239891 Acc@1: 0.425830 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.119742 Acc@1: 0.422363 \n",
      "\tTrain Epoch: 17 \tLoss: 2.178995 Acc@1: 0.412308 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.184790 Acc@1: 0.427377 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.194806 Acc@1: 0.435415 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.251442 Acc@1: 0.433789 \n",
      "\tTrain Epoch: 18 \tLoss: 2.254717 Acc@1: 0.443772 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.224193 Acc@1: 0.440180 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.244885 Acc@1: 0.436055 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.225314 Acc@1: 0.417773 \n",
      "\tTrain Epoch: 19 \tLoss: 2.225160 Acc@1: 0.410444 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.199972 Acc@1: 0.424775 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.241536 Acc@1: 0.421319 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.294753 Acc@1: 0.424316 \n",
      "\tTrain Epoch: 20 \tLoss: 2.294765 Acc@1: 0.432647 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 2.387040 Acc@1: 0.412505 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 2.371865 Acc@1: 0.415047 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.255959 Acc@1: 0.425391 \n",
      "\tTrain Epoch: 21 \tLoss: 2.167299 Acc@1: 0.451772 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 2.257898 Acc@1: 0.427416 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 2.288075 Acc@1: 0.427390 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.289491 Acc@1: 0.429199 \n",
      "\tTrain Epoch: 22 \tLoss: 2.412084 Acc@1: 0.425543 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.238441 Acc@1: 0.429394 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.280879 Acc@1: 0.422189 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.361706 Acc@1: 0.423926 \n",
      "\tTrain Epoch: 23 \tLoss: 2.386247 Acc@1: 0.405854 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.320293 Acc@1: 0.420838 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.351281 Acc@1: 0.415447 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.379585 Acc@1: 0.408203 \n",
      "\tTrain Epoch: 24 \tLoss: 2.349316 Acc@1: 0.403400 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.418703 Acc@1: 0.406272 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.412638 Acc@1: 0.407774 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.302302 Acc@1: 0.421191 \n",
      "\tTrain Epoch: 25 \tLoss: 2.322104 Acc@1: 0.410671 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.386248 Acc@1: 0.417295 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.333965 Acc@1: 0.415599 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.318739 Acc@1: 0.416992 \n",
      "\tTrain Epoch: 26 \tLoss: 2.336954 Acc@1: 0.414564 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.277135 Acc@1: 0.413044 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.296955 Acc@1: 0.414176 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.327943 Acc@1: 0.417871 \n",
      "\tTrain Epoch: 27 \tLoss: 2.423109 Acc@1: 0.416624 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.262266 Acc@1: 0.416642 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.282825 Acc@1: 0.418625 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.285545 Acc@1: 0.415430 \n",
      "\tTrain Epoch: 28 \tLoss: 2.262433 Acc@1: 0.429439 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 2.238627 Acc@1: 0.425450 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 2.265513 Acc@1: 0.426303 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.210765 Acc@1: 0.417090 \n",
      "\tTrain Epoch: 29 \tLoss: 2.267570 Acc@1: 0.406965 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 2.192753 Acc@1: 0.420021 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 2.230905 Acc@1: 0.414408 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.376772 Acc@1: 0.406055 \n",
      "\tTrain Epoch: 30 \tLoss: 2.289311 Acc@1: 0.425803 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 2.230222 Acc@1: 0.409441 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 2.249841 Acc@1: 0.409902 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.277158 Acc@1: 0.410449 \n",
      "\tTrain Epoch: 31 \tLoss: 2.264311 Acc@1: 0.430723 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 2.277124 Acc@1: 0.409530 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 2.235247 Acc@1: 0.407765 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.285005 Acc@1: 0.401465 \n",
      "\tTrain Epoch: 32 \tLoss: 2.342936 Acc@1: 0.395210 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 2.352686 Acc@1: 0.390756 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 2.290009 Acc@1: 0.396259 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.257210 Acc@1: 0.408301 \n",
      "\tTrain Epoch: 33 \tLoss: 2.155254 Acc@1: 0.413990 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 2.255617 Acc@1: 0.406001 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 2.280418 Acc@1: 0.405518 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 2.297935 Acc@1: 0.398828 \n",
      "\tTrain Epoch: 34 \tLoss: 2.239007 Acc@1: 0.414244 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 2.218472 Acc@1: 0.396354 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 2.231030 Acc@1: 0.391107 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.243827 Acc@1: 0.390234 \n",
      "\tTrain Epoch: 35 \tLoss: 2.228866 Acc@1: 0.396374 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 2.179845 Acc@1: 0.395793 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 2.203517 Acc@1: 0.397514 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.249403 Acc@1: 0.401465 \n",
      "\tTrain Epoch: 36 \tLoss: 2.239557 Acc@1: 0.395712 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 2.188447 Acc@1: 0.391755 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 2.185412 Acc@1: 0.395436 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.134566 Acc@1: 0.383984 \n",
      "\tTrain Epoch: 37 \tLoss: 2.199586 Acc@1: 0.378728 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 2.167058 Acc@1: 0.393242 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 2.160480 Acc@1: 0.394040 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.278965 Acc@1: 0.387305 \n",
      "\tTrain Epoch: 38 \tLoss: 2.312457 Acc@1: 0.391261 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 2.229256 Acc@1: 0.399617 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 2.200715 Acc@1: 0.400893 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.491962 Acc@1: 0.384570 \n",
      "\tTrain Epoch: 39 \tLoss: 2.444843 Acc@1: 0.395683 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 2.249335 Acc@1: 0.386401 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 2.187859 Acc@1: 0.391974 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.108370 Acc@1: 0.399609 \n",
      "\tTrain Epoch: 40 \tLoss: 2.086918 Acc@1: 0.396935 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 2.115405 Acc@1: 0.404219 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 2.144770 Acc@1: 0.404791 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.126943 Acc@1: 0.399219 \n",
      "\tTrain Epoch: 41 \tLoss: 2.176553 Acc@1: 0.382470 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 2.302336 Acc@1: 0.367299 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 2.280938 Acc@1: 0.375832 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.060914 Acc@1: 0.384473 \n",
      "\tTrain Epoch: 42 \tLoss: 2.061107 Acc@1: 0.385286 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 2.148716 Acc@1: 0.398770 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 2.129701 Acc@1: 0.399775 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.079169 Acc@1: 0.402051 \n",
      "\tTrain Epoch: 43 \tLoss: 2.022548 Acc@1: 0.397211 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.078304 Acc@1: 0.410010 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.093279 Acc@1: 0.408909 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.205346 Acc@1: 0.372656 \n",
      "\tTrain Epoch: 44 \tLoss: 2.139214 Acc@1: 0.386811 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 2.206528 Acc@1: 0.378350 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 2.206803 Acc@1: 0.371954 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.058466 Acc@1: 0.389648 \n",
      "\tTrain Epoch: 45 \tLoss: 1.996680 Acc@1: 0.405782 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 2.050440 Acc@1: 0.413756 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 2.071244 Acc@1: 0.404444 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.339048 Acc@1: 0.379004 \n",
      "\tTrain Epoch: 46 \tLoss: 2.320404 Acc@1: 0.395533 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 2.104075 Acc@1: 0.404689 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 2.089184 Acc@1: 0.407468 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.081664 Acc@1: 0.408496 \n",
      "\tTrain Epoch: 47 \tLoss: 2.081235 Acc@1: 0.413419 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 2.015042 Acc@1: 0.412905 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 2.039637 Acc@1: 0.410361 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.059897 Acc@1: 0.401465 \n",
      "\tTrain Epoch: 48 \tLoss: 2.020070 Acc@1: 0.417659 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 2.099151 Acc@1: 0.418759 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 2.112748 Acc@1: 0.416445 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.138954 Acc@1: 0.404297 \n",
      "\tTrain Epoch: 49 \tLoss: 2.112785 Acc@1: 0.418057 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 2.117044 Acc@1: 0.412015 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 2.146020 Acc@1: 0.398326 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.984464 Acc@1: 0.375195 \n",
      "\tTrain Epoch: 50 \tLoss: 2.012316 Acc@1: 0.377240 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 2.171577 Acc@1: 0.407434 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 2.236380 Acc@1: 0.394344 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.325441 Acc@1: 0.356055 \n",
      "\tTrain Epoch: 51 \tLoss: 2.312289 Acc@1: 0.379020 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 2.218314 Acc@1: 0.380181 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 2.165172 Acc@1: 0.387895 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.347939 Acc@1: 0.391895 \n",
      "\tTrain Epoch: 52 \tLoss: 2.300190 Acc@1: 0.407389 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 2.172901 Acc@1: 0.401739 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 2.186389 Acc@1: 0.390775 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.145673 Acc@1: 0.388281 \n",
      "\tTrain Epoch: 53 \tLoss: 2.068112 Acc@1: 0.404092 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 2.096545 Acc@1: 0.399633 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 2.091351 Acc@1: 0.399959 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.152716 Acc@1: 0.395117 \n",
      "\tTrain Epoch: 54 \tLoss: 2.118332 Acc@1: 0.395712 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 2.102595 Acc@1: 0.394742 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 2.102005 Acc@1: 0.394566 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 2.054586 Acc@1: 0.397266 \n",
      "\tTrain Epoch: 55 \tLoss: 1.986061 Acc@1: 0.407093 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 2.069238 Acc@1: 0.403063 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 2.102955 Acc@1: 0.402013 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.174493 Acc@1: 0.398828 \n",
      "\tTrain Epoch: 56 \tLoss: 2.167511 Acc@1: 0.414789 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 2.079534 Acc@1: 0.407776 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 2.180643 Acc@1: 0.397932 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.220067 Acc@1: 0.382520 \n",
      "\tTrain Epoch: 57 \tLoss: 2.185262 Acc@1: 0.389822 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 2.182952 Acc@1: 0.398441 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 2.183658 Acc@1: 0.397465 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.161555 Acc@1: 0.407129 \n",
      "\tTrain Epoch: 58 \tLoss: 2.084212 Acc@1: 0.413655 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 2.159398 Acc@1: 0.400800 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 2.190909 Acc@1: 0.395345 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.177179 Acc@1: 0.388379 \n",
      "\tTrain Epoch: 59 \tLoss: 2.209582 Acc@1: 0.400702 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 2.108400 Acc@1: 0.395377 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 2.127902 Acc@1: 0.395455 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.069966 Acc@1: 0.380273 \n",
      "\tTrain Epoch: 60 \tLoss: 2.062683 Acc@1: 0.366204 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 2.179554 Acc@1: 0.391862 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 2.159270 Acc@1: 0.390494 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.137562 Acc@1: 0.395508 \n",
      "\tTrain Epoch: 61 \tLoss: 2.028166 Acc@1: 0.394751 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 2.115774 Acc@1: 0.396791 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 2.152531 Acc@1: 0.396490 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.158051 Acc@1: 0.388574 \n",
      "\tTrain Epoch: 62 \tLoss: 2.106103 Acc@1: 0.387944 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 2.214071 Acc@1: 0.390374 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 2.190533 Acc@1: 0.386101 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.101168 Acc@1: 0.392773 \n",
      "\tTrain Epoch: 63 \tLoss: 2.250700 Acc@1: 0.371329 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 2.095936 Acc@1: 0.384673 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 2.109452 Acc@1: 0.385333 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.297746 Acc@1: 0.382422 \n",
      "\tTrain Epoch: 64 \tLoss: 2.338401 Acc@1: 0.381309 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 2.195036 Acc@1: 0.374427 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 2.176503 Acc@1: 0.374317 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.269006 Acc@1: 0.376465 \n",
      "\tTrain Epoch: 65 \tLoss: 2.404129 Acc@1: 0.373073 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 2.146275 Acc@1: 0.391877 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 2.167707 Acc@1: 0.387629 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.092256 Acc@1: 0.390625 \n",
      "\tTrain Epoch: 66 \tLoss: 2.108015 Acc@1: 0.373430 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 2.142613 Acc@1: 0.385254 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 2.119204 Acc@1: 0.386572 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.129174 Acc@1: 0.398730 \n",
      "\tTrain Epoch: 67 \tLoss: 2.150782 Acc@1: 0.391505 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 2.112187 Acc@1: 0.382737 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 2.117603 Acc@1: 0.384518 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 2.136285 Acc@1: 0.381836 \n",
      "\tTrain Epoch: 68 \tLoss: 2.121509 Acc@1: 0.380571 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 2.127881 Acc@1: 0.396027 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 2.123148 Acc@1: 0.395307 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.168225 Acc@1: 0.382715 \n",
      "\tTrain Epoch: 69 \tLoss: 2.142182 Acc@1: 0.383884 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 2.128155 Acc@1: 0.385243 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 2.123716 Acc@1: 0.379719 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.095523 Acc@1: 0.348926 \n",
      "\tTrain Epoch: 70 \tLoss: 2.074120 Acc@1: 0.350526 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 2.133277 Acc@1: 0.373079 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 2.150739 Acc@1: 0.371985 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.059062 Acc@1: 0.366797 \n",
      "\tTrain Epoch: 71 \tLoss: 2.046634 Acc@1: 0.363636 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 2.201834 Acc@1: 0.372224 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 2.187904 Acc@1: 0.376747 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.102086 Acc@1: 0.375195 \n",
      "\tTrain Epoch: 72 \tLoss: 2.061814 Acc@1: 0.370221 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 2.155857 Acc@1: 0.374365 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 2.169734 Acc@1: 0.376219 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.190622 Acc@1: 0.372949 \n",
      "\tTrain Epoch: 73 \tLoss: 2.172327 Acc@1: 0.396745 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 2.192397 Acc@1: 0.375809 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 2.203911 Acc@1: 0.380297 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.424266 Acc@1: 0.394824 \n",
      "\tTrain Epoch: 74 \tLoss: 2.352372 Acc@1: 0.417148 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 2.231699 Acc@1: 0.375510 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 2.260013 Acc@1: 0.375188 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.128502 Acc@1: 0.324219 \n",
      "\tTrain Epoch: 75 \tLoss: 2.092340 Acc@1: 0.335543 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 2.244622 Acc@1: 0.359904 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 2.232915 Acc@1: 0.364374 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.372922 Acc@1: 0.379883 \n",
      "\tTrain Epoch: 76 \tLoss: 2.323475 Acc@1: 0.393500 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 2.222809 Acc@1: 0.367829 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 2.238825 Acc@1: 0.369400 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 2.319787 Acc@1: 0.379980 \n",
      "\tTrain Epoch: 77 \tLoss: 2.438263 Acc@1: 0.368582 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 2.255166 Acc@1: 0.378175 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 2.243363 Acc@1: 0.377937 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 2.242097 Acc@1: 0.368945 \n",
      "\tTrain Epoch: 78 \tLoss: 2.223805 Acc@1: 0.380000 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 2.213557 Acc@1: 0.367013 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 2.205027 Acc@1: 0.367139 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 2.171136 Acc@1: 0.352148 \n",
      "\tTrain Epoch: 79 \tLoss: 2.238456 Acc@1: 0.342015 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 2.214018 Acc@1: 0.346493 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 2.240738 Acc@1: 0.350978 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 2.270624 Acc@1: 0.356641 \n",
      "\tTrain Epoch: 80 \tLoss: 2.356579 Acc@1: 0.345000 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 2.253575 Acc@1: 0.356005 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 2.261025 Acc@1: 0.360050 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 2.302444 Acc@1: 0.373340 \n",
      "\tTrain Epoch: 81 \tLoss: 2.430428 Acc@1: 0.360287 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 2.246035 Acc@1: 0.370867 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 2.234903 Acc@1: 0.367914 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 2.240401 Acc@1: 0.352148 \n",
      "\tTrain Epoch: 82 \tLoss: 2.262450 Acc@1: 0.355205 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 2.220806 Acc@1: 0.368907 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 2.227373 Acc@1: 0.364538 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 2.251453 Acc@1: 0.343555 \n",
      "\tTrain Epoch: 83 \tLoss: 2.218713 Acc@1: 0.358068 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 2.249892 Acc@1: 0.362049 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 2.258978 Acc@1: 0.362770 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 2.194311 Acc@1: 0.363867 \n",
      "\tTrain Epoch: 84 \tLoss: 2.238113 Acc@1: 0.346990 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 2.170877 Acc@1: 0.363545 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 2.201000 Acc@1: 0.362693 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 2.146410 Acc@1: 0.361035 \n",
      "\tTrain Epoch: 85 \tLoss: 2.089275 Acc@1: 0.363636 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 2.143559 Acc@1: 0.365169 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 2.149215 Acc@1: 0.362732 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 2.114896 Acc@1: 0.350195 \n",
      "\tTrain Epoch: 86 \tLoss: 2.123679 Acc@1: 0.367556 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 2.231930 Acc@1: 0.370527 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 2.202372 Acc@1: 0.366989 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 2.076909 Acc@1: 0.343848 \n",
      "\tTrain Epoch: 87 \tLoss: 2.087783 Acc@1: 0.343142 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 2.232896 Acc@1: 0.366366 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 2.233968 Acc@1: 0.362702 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 2.079710 Acc@1: 0.343555 \n",
      "\tTrain Epoch: 88 \tLoss: 2.071217 Acc@1: 0.356714 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 2.192062 Acc@1: 0.361657 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 2.192498 Acc@1: 0.363828 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 2.252217 Acc@1: 0.360742 \n",
      "\tTrain Epoch: 89 \tLoss: 2.327219 Acc@1: 0.353422 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 2.233282 Acc@1: 0.357401 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 2.225350 Acc@1: 0.359331 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 2.310923 Acc@1: 0.363281 \n",
      "\tTrain Epoch: 90 \tLoss: 2.336492 Acc@1: 0.345636 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 2.309333 Acc@1: 0.345370 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 2.272092 Acc@1: 0.347387 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 21:21:34:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 21:21:34:INFO:{'accuracy': 0.44248046875, 'accuracy_per_epoch': [0.2384765625, 0.31728515625, 0.3203125, 0.39140625, 0.4033203125, 0.4123046875, 0.412890625, 0.43115234375, 0.44248046875, 0.41826171875, 0.42373046875, 0.43740234375, 0.432421875, 0.4158203125, 0.41318359375, 0.42236328125, 0.4337890625, 0.4177734375, 0.42431640625, 0.425390625, 0.42919921875, 0.42392578125, 0.408203125, 0.42119140625, 0.4169921875, 0.41787109375, 0.4154296875, 0.41708984375, 0.4060546875, 0.41044921875, 0.40146484375, 0.40830078125, 0.398828125, 0.390234375, 0.40146484375, 0.383984375, 0.3873046875, 0.3845703125, 0.399609375, 0.39921875, 0.38447265625, 0.40205078125, 0.37265625, 0.3896484375, 0.37900390625, 0.40849609375, 0.40146484375, 0.404296875, 0.3751953125, 0.3560546875, 0.39189453125, 0.38828125, 0.3951171875, 0.397265625, 0.398828125, 0.38251953125, 0.40712890625, 0.38837890625, 0.3802734375, 0.3955078125, 0.38857421875, 0.3927734375, 0.382421875, 0.37646484375, 0.390625, 0.39873046875, 0.3818359375, 0.38271484375, 0.34892578125, 0.366796875, 0.3751953125, 0.37294921875, 0.39482421875, 0.32421875, 0.3798828125, 0.37998046875, 0.3689453125, 0.3521484375, 0.356640625, 0.37333984375, 0.3521484375, 0.3435546875, 0.3638671875, 0.36103515625, 0.3501953125, 0.34384765625, 0.3435546875, 0.3607421875, 0.36328125, 0.36103515625], 'avg_time_per_epoch_str': '0:00:08', 'time_per_epoch': [11.753285, 8.891913, 8.76369, 8.896442, 8.864686, 8.916426, 8.83826, 8.815035, 8.774129, 8.871614, 8.993598, 8.879288, 8.940546, 8.875438, 8.939878, 8.990419, 8.983814, 8.80753, 8.887294, 8.909225, 8.849829, 8.810764, 8.860847, 8.857785, 8.862654, 9.000636, 8.891399, 8.826694, 8.77836, 8.914545, 8.822711, 8.815109, 8.827539, 8.869445, 8.813944, 8.816726, 8.817868, 8.810488, 8.85848, 8.824692, 8.851522, 8.779245, 8.789256, 8.851798, 8.731633, 8.901737, 8.844783, 8.841294, 8.832184, 8.817206, 8.835775, 8.712476, 8.902593, 8.729682, 8.681833, 8.827217, 8.881351, 8.679404, 8.747834, 8.777751, 8.741854, 8.687848, 8.662089, 8.690008, 8.699794, 8.821133, 8.795452, 8.793957, 8.776343, 8.650556, 8.64202, 8.817679, 8.760266, 8.855158, 8.837657, 8.710558, 8.84806, 8.80471, 8.747404, 8.813377, 8.840208, 8.874455, 8.925998, 8.84393, 8.843822, 8.691328, 8.874292, 8.814597, 8.758252, 8.768486]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 2.389488 Acc@1: 0.361035 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='SimpleMech',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3) We test the learning effectiveness for Private learning for Opacus-DPCR with **TwoLevel model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **TwoLevel** achieves:\n",
    "Accuracy of **58.8%** and Loss of **1.31** after private training.\n",
    "Best Accuracy of **61.1%** and best Loss of **1.16** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with TwoLevel...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.301238 Acc@1: 0.103037 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.259081 Acc@1: 0.139097 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.323511 Acc@1: 0.237109 \n",
      "\tTrain Epoch: 2 \tLoss: 2.371215 Acc@1: 0.247585 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.311127 Acc@1: 0.244962 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.330320 Acc@1: 0.237507 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 1.989341 Acc@1: 0.269434 \n",
      "\tTrain Epoch: 3 \tLoss: 1.981314 Acc@1: 0.270769 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.015282 Acc@1: 0.260765 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.054368 Acc@1: 0.263904 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 1.978536 Acc@1: 0.300879 \n",
      "\tTrain Epoch: 4 \tLoss: 2.003875 Acc@1: 0.310704 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.046832 Acc@1: 0.295376 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.032855 Acc@1: 0.308286 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.857436 Acc@1: 0.311133 \n",
      "\tTrain Epoch: 5 \tLoss: 1.839839 Acc@1: 0.314213 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.857975 Acc@1: 0.322026 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.891049 Acc@1: 0.316220 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.934730 Acc@1: 0.327734 \n",
      "\tTrain Epoch: 6 \tLoss: 1.940987 Acc@1: 0.325223 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.949869 Acc@1: 0.337486 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.983911 Acc@1: 0.343030 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.841746 Acc@1: 0.331641 \n",
      "\tTrain Epoch: 7 \tLoss: 1.842374 Acc@1: 0.308846 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.813589 Acc@1: 0.340358 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.820058 Acc@1: 0.342546 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 1.810557 Acc@1: 0.348242 \n",
      "\tTrain Epoch: 8 \tLoss: 1.781634 Acc@1: 0.337169 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.844547 Acc@1: 0.354937 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.875099 Acc@1: 0.355321 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 1.694325 Acc@1: 0.388867 \n",
      "\tTrain Epoch: 9 \tLoss: 1.713774 Acc@1: 0.389754 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.741087 Acc@1: 0.383890 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.769457 Acc@1: 0.379998 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.836538 Acc@1: 0.367480 \n",
      "\tTrain Epoch: 10 \tLoss: 1.856522 Acc@1: 0.355302 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.900867 Acc@1: 0.383304 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.884556 Acc@1: 0.385543 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 1.718293 Acc@1: 0.389648 \n",
      "\tTrain Epoch: 11 \tLoss: 1.702165 Acc@1: 0.395719 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.689410 Acc@1: 0.397570 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.744411 Acc@1: 0.397443 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 1.830201 Acc@1: 0.383398 \n",
      "\tTrain Epoch: 12 \tLoss: 1.812643 Acc@1: 0.391347 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.856173 Acc@1: 0.394513 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.798916 Acc@1: 0.399488 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 1.679780 Acc@1: 0.410938 \n",
      "\tTrain Epoch: 13 \tLoss: 1.690939 Acc@1: 0.407762 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.704963 Acc@1: 0.414203 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.718272 Acc@1: 0.411825 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.834523 Acc@1: 0.415820 \n",
      "\tTrain Epoch: 14 \tLoss: 1.820380 Acc@1: 0.406805 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.846156 Acc@1: 0.403116 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.803009 Acc@1: 0.412150 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.609942 Acc@1: 0.436230 \n",
      "\tTrain Epoch: 15 \tLoss: 1.622509 Acc@1: 0.432148 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.661900 Acc@1: 0.427745 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.701364 Acc@1: 0.423573 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 1.848910 Acc@1: 0.402246 \n",
      "\tTrain Epoch: 16 \tLoss: 1.839167 Acc@1: 0.408859 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.858893 Acc@1: 0.406922 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.758677 Acc@1: 0.420701 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.622386 Acc@1: 0.428711 \n",
      "\tTrain Epoch: 17 \tLoss: 1.666201 Acc@1: 0.424615 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.668391 Acc@1: 0.434042 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.676656 Acc@1: 0.432655 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.787424 Acc@1: 0.403809 \n",
      "\tTrain Epoch: 18 \tLoss: 1.779711 Acc@1: 0.420575 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.766703 Acc@1: 0.424045 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.673028 Acc@1: 0.435786 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.573393 Acc@1: 0.455371 \n",
      "\tTrain Epoch: 19 \tLoss: 1.560694 Acc@1: 0.460713 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.650244 Acc@1: 0.445461 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.673023 Acc@1: 0.440070 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.705487 Acc@1: 0.426074 \n",
      "\tTrain Epoch: 20 \tLoss: 1.794857 Acc@1: 0.417855 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.676592 Acc@1: 0.435536 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.619533 Acc@1: 0.448783 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.560671 Acc@1: 0.464844 \n",
      "\tTrain Epoch: 21 \tLoss: 1.504930 Acc@1: 0.484252 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.578545 Acc@1: 0.458186 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.618383 Acc@1: 0.452331 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.798989 Acc@1: 0.435840 \n",
      "\tTrain Epoch: 22 \tLoss: 1.868147 Acc@1: 0.431095 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.691765 Acc@1: 0.439780 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.625380 Acc@1: 0.449494 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.554837 Acc@1: 0.471875 \n",
      "\tTrain Epoch: 23 \tLoss: 1.552616 Acc@1: 0.463415 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.610619 Acc@1: 0.466853 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.639090 Acc@1: 0.461191 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.739492 Acc@1: 0.449219 \n",
      "\tTrain Epoch: 24 \tLoss: 1.757610 Acc@1: 0.452859 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.615873 Acc@1: 0.459573 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.569902 Acc@1: 0.466352 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.594556 Acc@1: 0.461719 \n",
      "\tTrain Epoch: 25 \tLoss: 1.649134 Acc@1: 0.461576 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.571778 Acc@1: 0.467743 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.620151 Acc@1: 0.461838 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.632562 Acc@1: 0.462891 \n",
      "\tTrain Epoch: 26 \tLoss: 1.604784 Acc@1: 0.466921 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.519294 Acc@1: 0.480679 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.513054 Acc@1: 0.481810 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.518934 Acc@1: 0.478027 \n",
      "\tTrain Epoch: 27 \tLoss: 1.560393 Acc@1: 0.479220 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.540410 Acc@1: 0.486334 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.601287 Acc@1: 0.482413 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.513429 Acc@1: 0.492285 \n",
      "\tTrain Epoch: 28 \tLoss: 1.476561 Acc@1: 0.492666 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.484885 Acc@1: 0.492795 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.486683 Acc@1: 0.491057 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.611751 Acc@1: 0.467480 \n",
      "\tTrain Epoch: 29 \tLoss: 1.697976 Acc@1: 0.476119 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.637294 Acc@1: 0.470988 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.658381 Acc@1: 0.465109 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.460888 Acc@1: 0.488086 \n",
      "\tTrain Epoch: 30 \tLoss: 1.439964 Acc@1: 0.517593 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.454383 Acc@1: 0.497443 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.469646 Acc@1: 0.496287 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.508933 Acc@1: 0.492090 \n",
      "\tTrain Epoch: 31 \tLoss: 1.545985 Acc@1: 0.492972 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.551719 Acc@1: 0.488959 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.569949 Acc@1: 0.488072 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.452398 Acc@1: 0.494336 \n",
      "\tTrain Epoch: 32 \tLoss: 1.403573 Acc@1: 0.511976 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.454607 Acc@1: 0.501092 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.476726 Acc@1: 0.498271 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.538947 Acc@1: 0.485449 \n",
      "\tTrain Epoch: 33 \tLoss: 1.479556 Acc@1: 0.504663 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.569417 Acc@1: 0.488525 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.587023 Acc@1: 0.491291 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.445849 Acc@1: 0.517480 \n",
      "\tTrain Epoch: 34 \tLoss: 1.426393 Acc@1: 0.519380 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.445984 Acc@1: 0.513971 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.488716 Acc@1: 0.508166 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.525519 Acc@1: 0.504297 \n",
      "\tTrain Epoch: 35 \tLoss: 1.542916 Acc@1: 0.517393 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.548111 Acc@1: 0.501876 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.543775 Acc@1: 0.503441 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.465982 Acc@1: 0.520605 \n",
      "\tTrain Epoch: 36 \tLoss: 1.487858 Acc@1: 0.493665 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.411834 Acc@1: 0.518531 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.435346 Acc@1: 0.517008 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.557786 Acc@1: 0.491113 \n",
      "\tTrain Epoch: 37 \tLoss: 1.569455 Acc@1: 0.499006 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.567165 Acc@1: 0.505040 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.553128 Acc@1: 0.508146 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.465567 Acc@1: 0.518457 \n",
      "\tTrain Epoch: 38 \tLoss: 1.427321 Acc@1: 0.516385 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.423205 Acc@1: 0.522093 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.439206 Acc@1: 0.522562 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.604725 Acc@1: 0.500586 \n",
      "\tTrain Epoch: 39 \tLoss: 1.558074 Acc@1: 0.512710 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.575089 Acc@1: 0.508365 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.502822 Acc@1: 0.516095 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.385073 Acc@1: 0.531152 \n",
      "\tTrain Epoch: 40 \tLoss: 1.368035 Acc@1: 0.535838 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.378576 Acc@1: 0.536423 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.410048 Acc@1: 0.529656 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.527233 Acc@1: 0.499219 \n",
      "\tTrain Epoch: 41 \tLoss: 1.505859 Acc@1: 0.520916 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.496794 Acc@1: 0.520861 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.450015 Acc@1: 0.532581 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.375761 Acc@1: 0.537500 \n",
      "\tTrain Epoch: 42 \tLoss: 1.387992 Acc@1: 0.541626 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.432821 Acc@1: 0.534481 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.449071 Acc@1: 0.530841 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.586775 Acc@1: 0.505273 \n",
      "\tTrain Epoch: 43 \tLoss: 1.564684 Acc@1: 0.505682 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.499619 Acc@1: 0.519509 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.425935 Acc@1: 0.536963 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.385578 Acc@1: 0.540234 \n",
      "\tTrain Epoch: 44 \tLoss: 1.347177 Acc@1: 0.555118 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.384093 Acc@1: 0.546432 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.433589 Acc@1: 0.543474 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.550224 Acc@1: 0.517090 \n",
      "\tTrain Epoch: 45 \tLoss: 1.510027 Acc@1: 0.529169 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.461037 Acc@1: 0.535859 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.399682 Acc@1: 0.546881 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.355154 Acc@1: 0.557520 \n",
      "\tTrain Epoch: 46 \tLoss: 1.337741 Acc@1: 0.564268 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.371583 Acc@1: 0.549036 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.403560 Acc@1: 0.543667 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.441740 Acc@1: 0.529492 \n",
      "\tTrain Epoch: 47 \tLoss: 1.437748 Acc@1: 0.539221 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.467583 Acc@1: 0.541720 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.414437 Acc@1: 0.547350 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.409313 Acc@1: 0.556250 \n",
      "\tTrain Epoch: 48 \tLoss: 1.397175 Acc@1: 0.563492 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.405850 Acc@1: 0.557191 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.402966 Acc@1: 0.548922 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.541114 Acc@1: 0.526074 \n",
      "\tTrain Epoch: 49 \tLoss: 1.543916 Acc@1: 0.518646 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.371604 Acc@1: 0.553909 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.339795 Acc@1: 0.560066 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.355416 Acc@1: 0.560645 \n",
      "\tTrain Epoch: 50 \tLoss: 1.365626 Acc@1: 0.551090 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.353872 Acc@1: 0.560910 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.381707 Acc@1: 0.555078 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.468525 Acc@1: 0.555078 \n",
      "\tTrain Epoch: 51 \tLoss: 1.557310 Acc@1: 0.536863 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.355123 Acc@1: 0.563475 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.326812 Acc@1: 0.566734 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.398201 Acc@1: 0.556250 \n",
      "\tTrain Epoch: 52 \tLoss: 1.363346 Acc@1: 0.568647 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.390558 Acc@1: 0.562383 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.436150 Acc@1: 0.551566 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.403566 Acc@1: 0.563867 \n",
      "\tTrain Epoch: 53 \tLoss: 1.351931 Acc@1: 0.584655 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.349735 Acc@1: 0.570102 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.351147 Acc@1: 0.568238 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.383042 Acc@1: 0.547656 \n",
      "\tTrain Epoch: 54 \tLoss: 1.352212 Acc@1: 0.548246 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.394204 Acc@1: 0.549937 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.430072 Acc@1: 0.549448 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.353835 Acc@1: 0.560645 \n",
      "\tTrain Epoch: 55 \tLoss: 1.268492 Acc@1: 0.575924 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.296149 Acc@1: 0.575116 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.307859 Acc@1: 0.573350 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.405337 Acc@1: 0.555273 \n",
      "\tTrain Epoch: 56 \tLoss: 1.387221 Acc@1: 0.557786 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.419213 Acc@1: 0.561114 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.432382 Acc@1: 0.555981 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.338286 Acc@1: 0.572168 \n",
      "\tTrain Epoch: 57 \tLoss: 1.250769 Acc@1: 0.599308 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.269253 Acc@1: 0.582207 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.295235 Acc@1: 0.579462 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.406341 Acc@1: 0.555664 \n",
      "\tTrain Epoch: 58 \tLoss: 1.360329 Acc@1: 0.570281 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.424072 Acc@1: 0.564299 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.425366 Acc@1: 0.562207 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.284795 Acc@1: 0.569434 \n",
      "\tTrain Epoch: 59 \tLoss: 1.244929 Acc@1: 0.584754 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.284676 Acc@1: 0.581279 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.289541 Acc@1: 0.581677 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.350040 Acc@1: 0.560937 \n",
      "\tTrain Epoch: 60 \tLoss: 1.351762 Acc@1: 0.561890 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.382202 Acc@1: 0.556555 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.365016 Acc@1: 0.563698 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.262378 Acc@1: 0.577832 \n",
      "\tTrain Epoch: 61 \tLoss: 1.226681 Acc@1: 0.605249 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.280211 Acc@1: 0.590928 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.313652 Acc@1: 0.581446 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.411435 Acc@1: 0.557520 \n",
      "\tTrain Epoch: 62 \tLoss: 1.358753 Acc@1: 0.567233 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.402658 Acc@1: 0.555089 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.376085 Acc@1: 0.564122 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.332080 Acc@1: 0.565234 \n",
      "\tTrain Epoch: 63 \tLoss: 1.218493 Acc@1: 0.612245 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.277304 Acc@1: 0.590810 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.286765 Acc@1: 0.587555 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.387687 Acc@1: 0.551270 \n",
      "\tTrain Epoch: 64 \tLoss: 1.328414 Acc@1: 0.569215 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.387950 Acc@1: 0.566562 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.359199 Acc@1: 0.572924 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.328102 Acc@1: 0.582031 \n",
      "\tTrain Epoch: 65 \tLoss: 1.306991 Acc@1: 0.600719 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.307837 Acc@1: 0.583525 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.308689 Acc@1: 0.579223 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.368642 Acc@1: 0.556641 \n",
      "\tTrain Epoch: 66 \tLoss: 1.420558 Acc@1: 0.554589 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.396142 Acc@1: 0.559213 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.314572 Acc@1: 0.579479 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.222291 Acc@1: 0.588574 \n",
      "\tTrain Epoch: 67 \tLoss: 1.184418 Acc@1: 0.626919 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.224322 Acc@1: 0.596809 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.270258 Acc@1: 0.590672 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.435409 Acc@1: 0.562207 \n",
      "\tTrain Epoch: 68 \tLoss: 1.438886 Acc@1: 0.578368 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 1.361569 Acc@1: 0.590756 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 1.298880 Acc@1: 0.590887 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.225925 Acc@1: 0.582520 \n",
      "\tTrain Epoch: 69 \tLoss: 1.199715 Acc@1: 0.600601 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.268278 Acc@1: 0.584951 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.278205 Acc@1: 0.584226 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.451640 Acc@1: 0.558203 \n",
      "\tTrain Epoch: 70 \tLoss: 1.401631 Acc@1: 0.573861 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.333430 Acc@1: 0.590114 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.260343 Acc@1: 0.599146 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.251787 Acc@1: 0.595117 \n",
      "\tTrain Epoch: 71 \tLoss: 1.179787 Acc@1: 0.608202 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.241082 Acc@1: 0.600742 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.259332 Acc@1: 0.593462 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.397791 Acc@1: 0.562402 \n",
      "\tTrain Epoch: 72 \tLoss: 1.351430 Acc@1: 0.576459 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.225807 Acc@1: 0.607782 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.229392 Acc@1: 0.607639 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.307220 Acc@1: 0.595117 \n",
      "\tTrain Epoch: 73 \tLoss: 1.217641 Acc@1: 0.602747 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.290373 Acc@1: 0.598012 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.330528 Acc@1: 0.592276 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.374540 Acc@1: 0.574316 \n",
      "\tTrain Epoch: 74 \tLoss: 1.375403 Acc@1: 0.593931 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.247921 Acc@1: 0.605217 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.210028 Acc@1: 0.607655 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.271373 Acc@1: 0.587402 \n",
      "\tTrain Epoch: 75 \tLoss: 1.272484 Acc@1: 0.582866 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.275473 Acc@1: 0.596456 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.324978 Acc@1: 0.588271 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.262459 Acc@1: 0.590820 \n",
      "\tTrain Epoch: 76 \tLoss: 1.222807 Acc@1: 0.623000 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.206561 Acc@1: 0.603400 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.200678 Acc@1: 0.608754 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.344647 Acc@1: 0.586133 \n",
      "\tTrain Epoch: 77 \tLoss: 1.363307 Acc@1: 0.589222 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 1.298140 Acc@1: 0.594832 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 1.342045 Acc@1: 0.589197 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.361111 Acc@1: 0.584082 \n",
      "\tTrain Epoch: 78 \tLoss: 1.337151 Acc@1: 0.604390 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.212632 Acc@1: 0.609452 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.208931 Acc@1: 0.611986 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.375157 Acc@1: 0.581543 \n",
      "\tTrain Epoch: 79 \tLoss: 1.327343 Acc@1: 0.592138 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.329267 Acc@1: 0.586449 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.319814 Acc@1: 0.585674 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 1.274487 Acc@1: 0.598730 \n",
      "\tTrain Epoch: 80 \tLoss: 1.272604 Acc@1: 0.613000 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.203264 Acc@1: 0.618105 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.209493 Acc@1: 0.613941 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.267158 Acc@1: 0.581152 \n",
      "\tTrain Epoch: 81 \tLoss: 1.197590 Acc@1: 0.606960 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.247138 Acc@1: 0.595004 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.292635 Acc@1: 0.595524 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.215231 Acc@1: 0.600488 \n",
      "\tTrain Epoch: 82 \tLoss: 1.182984 Acc@1: 0.605821 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.173380 Acc@1: 0.618229 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.196767 Acc@1: 0.616129 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.330845 Acc@1: 0.589746 \n",
      "\tTrain Epoch: 83 \tLoss: 1.245330 Acc@1: 0.602092 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.357589 Acc@1: 0.586701 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.330003 Acc@1: 0.594535 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.161854 Acc@1: 0.610840 \n",
      "\tTrain Epoch: 84 \tLoss: 1.139217 Acc@1: 0.611027 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 1.178812 Acc@1: 0.614726 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 1.188750 Acc@1: 0.613337 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.336595 Acc@1: 0.578711 \n",
      "\tTrain Epoch: 85 \tLoss: 1.262688 Acc@1: 0.594444 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.330034 Acc@1: 0.593031 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.294964 Acc@1: 0.597383 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.217117 Acc@1: 0.603711 \n",
      "\tTrain Epoch: 86 \tLoss: 1.159299 Acc@1: 0.619097 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 1.194148 Acc@1: 0.621931 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 1.209374 Acc@1: 0.617926 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.300097 Acc@1: 0.594141 \n",
      "\tTrain Epoch: 87 \tLoss: 1.283484 Acc@1: 0.600499 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.332193 Acc@1: 0.599145 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.300990 Acc@1: 0.607920 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.239434 Acc@1: 0.608105 \n",
      "\tTrain Epoch: 88 \tLoss: 1.221902 Acc@1: 0.620674 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 1.194780 Acc@1: 0.614428 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 1.191963 Acc@1: 0.612741 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.301525 Acc@1: 0.589648 \n",
      "\tTrain Epoch: 89 \tLoss: 1.271465 Acc@1: 0.593463 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.327807 Acc@1: 0.596657 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.263238 Acc@1: 0.607385 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.195887 Acc@1: 0.608984 \n",
      "\tTrain Epoch: 90 \tLoss: 1.167969 Acc@1: 0.615461 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 1.184880 Acc@1: 0.621597 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 1.217490 Acc@1: 0.614319 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 21:42:35:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 21:42:35:INFO:{'accuracy': 0.61083984375, 'accuracy_per_epoch': [0.237109375, 0.26943359375, 0.30087890625, 0.3111328125, 0.327734375, 0.331640625, 0.3482421875, 0.3888671875, 0.36748046875, 0.3896484375, 0.3833984375, 0.4109375, 0.4158203125, 0.43623046875, 0.40224609375, 0.4287109375, 0.40380859375, 0.45537109375, 0.42607421875, 0.46484375, 0.43583984375, 0.471875, 0.44921875, 0.46171875, 0.462890625, 0.47802734375, 0.49228515625, 0.46748046875, 0.4880859375, 0.49208984375, 0.4943359375, 0.48544921875, 0.51748046875, 0.504296875, 0.52060546875, 0.49111328125, 0.51845703125, 0.5005859375, 0.53115234375, 0.49921875, 0.5375, 0.5052734375, 0.540234375, 0.51708984375, 0.55751953125, 0.5294921875, 0.55625, 0.52607421875, 0.56064453125, 0.555078125, 0.55625, 0.5638671875, 0.54765625, 0.56064453125, 0.5552734375, 0.57216796875, 0.5556640625, 0.56943359375, 0.5609375, 0.57783203125, 0.55751953125, 0.565234375, 0.55126953125, 0.58203125, 0.556640625, 0.58857421875, 0.56220703125, 0.58251953125, 0.558203125, 0.5951171875, 0.56240234375, 0.5951171875, 0.57431640625, 0.58740234375, 0.5908203125, 0.5861328125, 0.58408203125, 0.58154296875, 0.59873046875, 0.58115234375, 0.60048828125, 0.58974609375, 0.61083984375, 0.5787109375, 0.6037109375, 0.594140625, 0.60810546875, 0.5896484375, 0.608984375, 0.5876953125], 'avg_time_per_epoch_str': '0:00:08', 'time_per_epoch': [11.831289, 8.961527, 8.865831, 8.919143, 8.924109, 9.022145, 8.913899, 8.888965, 8.910503, 8.94703, 8.966983, 8.91279, 8.921816, 8.780249, 8.762216, 8.842309, 8.818041, 8.819127, 8.789315, 8.82452, 8.824321, 8.753174, 8.857806, 8.774213, 8.887085, 8.8273, 8.766254, 8.790763, 8.897057, 8.918371, 8.93056, 8.903509, 8.883031, 8.900545, 8.851089, 8.848013, 8.923599, 8.857064, 8.932434, 8.878099, 8.881554, 8.834943, 8.900158, 8.84637, 8.805102, 8.865565, 8.869249, 8.913708, 8.912615, 8.812881, 8.839605, 8.770204, 8.985918, 8.887049, 8.763487, 8.9112, 8.909015, 8.900432, 8.953861, 8.899667, 8.815817, 8.958116, 8.940474, 8.732157, 8.894795, 8.848027, 8.848061, 8.879216, 8.846397, 8.817692, 8.744617, 8.934978, 8.863419, 8.900716, 8.82168, 8.857485, 8.829342, 8.93667, 8.847221, 8.903208, 8.941834, 8.975643, 9.143031, 8.86879, 9.031674, 9.259491, 8.867025, 8.889263, 8.782217, 8.840063]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.306080 Acc@1: 0.587695 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='TwoLevel',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(4) We test the learning effectiveness for Private learning for Opacus-DPCR with **BinMech model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **BinMech** achieves:\n",
    "Accuracy of **64.2%** and Loss of **1.09** after private training.\n",
    "Best Accuracy of **64.2%** and best Loss of **1.14** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with BinMech...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.303621 Acc@1: 0.101463 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.297530 Acc@1: 0.108375 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.186121 Acc@1: 0.156641 \n",
      "\tTrain Epoch: 2 \tLoss: 2.202749 Acc@1: 0.140824 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.158295 Acc@1: 0.204526 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.124934 Acc@1: 0.217337 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.053870 Acc@1: 0.284961 \n",
      "\tTrain Epoch: 3 \tLoss: 2.052793 Acc@1: 0.300000 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.028334 Acc@1: 0.270416 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.015534 Acc@1: 0.274505 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 1.933085 Acc@1: 0.304004 \n",
      "\tTrain Epoch: 4 \tLoss: 1.972031 Acc@1: 0.290387 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.026377 Acc@1: 0.278483 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.977091 Acc@1: 0.289119 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.874098 Acc@1: 0.325586 \n",
      "\tTrain Epoch: 5 \tLoss: 1.869107 Acc@1: 0.318274 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.868012 Acc@1: 0.331196 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.864117 Acc@1: 0.333956 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.954717 Acc@1: 0.359668 \n",
      "\tTrain Epoch: 6 \tLoss: 1.980248 Acc@1: 0.363456 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.903253 Acc@1: 0.326542 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.870336 Acc@1: 0.332576 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.802717 Acc@1: 0.354590 \n",
      "\tTrain Epoch: 7 \tLoss: 1.788735 Acc@1: 0.339369 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.826408 Acc@1: 0.357036 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.805759 Acc@1: 0.362638 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 1.743251 Acc@1: 0.391211 \n",
      "\tTrain Epoch: 8 \tLoss: 1.743318 Acc@1: 0.372186 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.760210 Acc@1: 0.385482 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.808852 Acc@1: 0.381758 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 1.734665 Acc@1: 0.396875 \n",
      "\tTrain Epoch: 9 \tLoss: 1.718476 Acc@1: 0.411853 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.720983 Acc@1: 0.397195 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.752599 Acc@1: 0.395922 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.786574 Acc@1: 0.386816 \n",
      "\tTrain Epoch: 10 \tLoss: 1.782912 Acc@1: 0.383548 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.739996 Acc@1: 0.389693 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.728384 Acc@1: 0.396466 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 1.765487 Acc@1: 0.404883 \n",
      "\tTrain Epoch: 11 \tLoss: 1.810257 Acc@1: 0.404679 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.756085 Acc@1: 0.407380 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.714126 Acc@1: 0.405710 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 1.654030 Acc@1: 0.411816 \n",
      "\tTrain Epoch: 12 \tLoss: 1.667482 Acc@1: 0.398639 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.708207 Acc@1: 0.403081 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.744870 Acc@1: 0.400237 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 1.679028 Acc@1: 0.404590 \n",
      "\tTrain Epoch: 13 \tLoss: 1.673593 Acc@1: 0.414315 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.760153 Acc@1: 0.407015 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.718376 Acc@1: 0.409287 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.607946 Acc@1: 0.423340 \n",
      "\tTrain Epoch: 14 \tLoss: 1.609118 Acc@1: 0.412722 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.636852 Acc@1: 0.426549 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.640854 Acc@1: 0.428031 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.739474 Acc@1: 0.403809 \n",
      "\tTrain Epoch: 15 \tLoss: 1.758823 Acc@1: 0.393090 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.662976 Acc@1: 0.427212 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.662037 Acc@1: 0.432776 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 1.594836 Acc@1: 0.447266 \n",
      "\tTrain Epoch: 16 \tLoss: 1.617044 Acc@1: 0.440428 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.682719 Acc@1: 0.442194 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.636333 Acc@1: 0.444366 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.652860 Acc@1: 0.430273 \n",
      "\tTrain Epoch: 17 \tLoss: 1.728490 Acc@1: 0.414872 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.607417 Acc@1: 0.441372 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.614847 Acc@1: 0.444264 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.579241 Acc@1: 0.436816 \n",
      "\tTrain Epoch: 18 \tLoss: 1.576322 Acc@1: 0.448815 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.597352 Acc@1: 0.449891 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.589864 Acc@1: 0.453006 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.601272 Acc@1: 0.463965 \n",
      "\tTrain Epoch: 19 \tLoss: 1.608998 Acc@1: 0.458272 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.586652 Acc@1: 0.459648 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.586273 Acc@1: 0.456603 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.665188 Acc@1: 0.453320 \n",
      "\tTrain Epoch: 20 \tLoss: 1.664207 Acc@1: 0.462758 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.640709 Acc@1: 0.461965 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.602266 Acc@1: 0.463225 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.613875 Acc@1: 0.461719 \n",
      "\tTrain Epoch: 21 \tLoss: 1.564687 Acc@1: 0.496063 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.603827 Acc@1: 0.466044 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.576782 Acc@1: 0.464673 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.745950 Acc@1: 0.428223 \n",
      "\tTrain Epoch: 22 \tLoss: 1.772882 Acc@1: 0.439172 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.617225 Acc@1: 0.444506 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.611723 Acc@1: 0.447598 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.546392 Acc@1: 0.450391 \n",
      "\tTrain Epoch: 23 \tLoss: 1.552155 Acc@1: 0.455610 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.597635 Acc@1: 0.454262 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.607837 Acc@1: 0.455853 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.625014 Acc@1: 0.461035 \n",
      "\tTrain Epoch: 24 \tLoss: 1.633294 Acc@1: 0.474498 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.529013 Acc@1: 0.479201 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.525919 Acc@1: 0.478109 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.579399 Acc@1: 0.457617 \n",
      "\tTrain Epoch: 25 \tLoss: 1.578875 Acc@1: 0.457660 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.559184 Acc@1: 0.472024 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.543597 Acc@1: 0.473716 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.544064 Acc@1: 0.482910 \n",
      "\tTrain Epoch: 26 \tLoss: 1.549705 Acc@1: 0.491195 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.557538 Acc@1: 0.489070 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.529852 Acc@1: 0.487573 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.453165 Acc@1: 0.486914 \n",
      "\tTrain Epoch: 27 \tLoss: 1.503812 Acc@1: 0.485890 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.473435 Acc@1: 0.499302 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.508296 Acc@1: 0.498860 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.457604 Acc@1: 0.500977 \n",
      "\tTrain Epoch: 28 \tLoss: 1.397982 Acc@1: 0.497218 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.471218 Acc@1: 0.500351 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.471588 Acc@1: 0.499637 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.554762 Acc@1: 0.491797 \n",
      "\tTrain Epoch: 29 \tLoss: 1.644067 Acc@1: 0.485075 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.533831 Acc@1: 0.499339 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.492063 Acc@1: 0.501462 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.456043 Acc@1: 0.507324 \n",
      "\tTrain Epoch: 30 \tLoss: 1.414315 Acc@1: 0.532891 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.455982 Acc@1: 0.513332 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.461390 Acc@1: 0.512307 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.423759 Acc@1: 0.524609 \n",
      "\tTrain Epoch: 31 \tLoss: 1.435403 Acc@1: 0.534639 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.431702 Acc@1: 0.526256 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.436768 Acc@1: 0.526879 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.407741 Acc@1: 0.519531 \n",
      "\tTrain Epoch: 32 \tLoss: 1.376399 Acc@1: 0.546407 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.411234 Acc@1: 0.521441 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.428008 Acc@1: 0.523216 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.480639 Acc@1: 0.500879 \n",
      "\tTrain Epoch: 33 \tLoss: 1.404213 Acc@1: 0.523834 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.429035 Acc@1: 0.523489 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.405762 Acc@1: 0.526812 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.416494 Acc@1: 0.522461 \n",
      "\tTrain Epoch: 34 \tLoss: 1.392180 Acc@1: 0.523740 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.442260 Acc@1: 0.526758 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.448160 Acc@1: 0.527901 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.437849 Acc@1: 0.525879 \n",
      "\tTrain Epoch: 35 \tLoss: 1.417460 Acc@1: 0.550710 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.465789 Acc@1: 0.530365 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.436274 Acc@1: 0.533316 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.423500 Acc@1: 0.522949 \n",
      "\tTrain Epoch: 36 \tLoss: 1.434561 Acc@1: 0.515595 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.379602 Acc@1: 0.539727 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.415051 Acc@1: 0.537491 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.397954 Acc@1: 0.534570 \n",
      "\tTrain Epoch: 37 \tLoss: 1.376711 Acc@1: 0.545229 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.390186 Acc@1: 0.536026 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.384794 Acc@1: 0.537564 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.398085 Acc@1: 0.522559 \n",
      "\tTrain Epoch: 38 \tLoss: 1.374228 Acc@1: 0.550149 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.393861 Acc@1: 0.543574 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.384944 Acc@1: 0.549695 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.430322 Acc@1: 0.535547 \n",
      "\tTrain Epoch: 39 \tLoss: 1.391625 Acc@1: 0.555875 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.369999 Acc@1: 0.548465 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.378603 Acc@1: 0.548597 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.379453 Acc@1: 0.536523 \n",
      "\tTrain Epoch: 40 \tLoss: 1.366374 Acc@1: 0.534849 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.349966 Acc@1: 0.549380 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.408163 Acc@1: 0.543008 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.376958 Acc@1: 0.532813 \n",
      "\tTrain Epoch: 41 \tLoss: 1.357740 Acc@1: 0.555777 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.359803 Acc@1: 0.554176 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.360214 Acc@1: 0.555509 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.525523 Acc@1: 0.521094 \n",
      "\tTrain Epoch: 42 \tLoss: 1.552859 Acc@1: 0.520813 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.425676 Acc@1: 0.527440 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.403465 Acc@1: 0.530260 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.444105 Acc@1: 0.527344 \n",
      "\tTrain Epoch: 43 \tLoss: 1.496378 Acc@1: 0.502583 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.372502 Acc@1: 0.534482 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.358313 Acc@1: 0.541964 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.394910 Acc@1: 0.537891 \n",
      "\tTrain Epoch: 44 \tLoss: 1.346968 Acc@1: 0.544783 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.397379 Acc@1: 0.537270 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.402992 Acc@1: 0.542376 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.355846 Acc@1: 0.541992 \n",
      "\tTrain Epoch: 45 \tLoss: 1.303676 Acc@1: 0.553949 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.335212 Acc@1: 0.555976 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.344624 Acc@1: 0.555241 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.410933 Acc@1: 0.554297 \n",
      "\tTrain Epoch: 46 \tLoss: 1.339178 Acc@1: 0.577667 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.378830 Acc@1: 0.551124 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.352415 Acc@1: 0.552266 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.399449 Acc@1: 0.545117 \n",
      "\tTrain Epoch: 47 \tLoss: 1.366733 Acc@1: 0.535274 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.375348 Acc@1: 0.551804 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.345219 Acc@1: 0.558073 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.338865 Acc@1: 0.564551 \n",
      "\tTrain Epoch: 48 \tLoss: 1.272368 Acc@1: 0.572421 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.293774 Acc@1: 0.569099 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.289111 Acc@1: 0.570344 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.347594 Acc@1: 0.547754 \n",
      "\tTrain Epoch: 49 \tLoss: 1.349301 Acc@1: 0.531894 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.288707 Acc@1: 0.568896 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.310343 Acc@1: 0.567723 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.338820 Acc@1: 0.566016 \n",
      "\tTrain Epoch: 50 \tLoss: 1.325617 Acc@1: 0.576755 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.300886 Acc@1: 0.580682 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.316999 Acc@1: 0.576513 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.324493 Acc@1: 0.557227 \n",
      "\tTrain Epoch: 51 \tLoss: 1.374910 Acc@1: 0.555666 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.278596 Acc@1: 0.575403 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.289838 Acc@1: 0.575373 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.405951 Acc@1: 0.556348 \n",
      "\tTrain Epoch: 52 \tLoss: 1.356235 Acc@1: 0.569646 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.335365 Acc@1: 0.572207 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.312645 Acc@1: 0.573091 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.279304 Acc@1: 0.566895 \n",
      "\tTrain Epoch: 53 \tLoss: 1.248473 Acc@1: 0.579028 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.255957 Acc@1: 0.574154 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.244347 Acc@1: 0.582533 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.263669 Acc@1: 0.583301 \n",
      "\tTrain Epoch: 54 \tLoss: 1.273988 Acc@1: 0.576511 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.272574 Acc@1: 0.586944 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.278385 Acc@1: 0.587890 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.222998 Acc@1: 0.592090 \n",
      "\tTrain Epoch: 55 \tLoss: 1.173127 Acc@1: 0.603397 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.292965 Acc@1: 0.587617 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.287351 Acc@1: 0.588164 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.299617 Acc@1: 0.580957 \n",
      "\tTrain Epoch: 56 \tLoss: 1.286839 Acc@1: 0.579334 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.245411 Acc@1: 0.590717 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.255105 Acc@1: 0.590279 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.285020 Acc@1: 0.582520 \n",
      "\tTrain Epoch: 57 \tLoss: 1.207991 Acc@1: 0.605237 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.309338 Acc@1: 0.588109 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.271589 Acc@1: 0.592078 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.216081 Acc@1: 0.595605 \n",
      "\tTrain Epoch: 58 \tLoss: 1.207252 Acc@1: 0.597390 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.249524 Acc@1: 0.595765 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.251858 Acc@1: 0.596159 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.273489 Acc@1: 0.591309 \n",
      "\tTrain Epoch: 59 \tLoss: 1.245736 Acc@1: 0.606820 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.256218 Acc@1: 0.596250 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.259726 Acc@1: 0.595006 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.294833 Acc@1: 0.588379 \n",
      "\tTrain Epoch: 60 \tLoss: 1.304002 Acc@1: 0.592193 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.219892 Acc@1: 0.603945 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.218264 Acc@1: 0.600739 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.248635 Acc@1: 0.589551 \n",
      "\tTrain Epoch: 61 \tLoss: 1.225504 Acc@1: 0.607349 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.262167 Acc@1: 0.603942 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.265750 Acc@1: 0.597786 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.292593 Acc@1: 0.583203 \n",
      "\tTrain Epoch: 62 \tLoss: 1.328657 Acc@1: 0.587326 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.259676 Acc@1: 0.596386 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.253198 Acc@1: 0.593415 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.230422 Acc@1: 0.585449 \n",
      "\tTrain Epoch: 63 \tLoss: 1.209454 Acc@1: 0.597810 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.234201 Acc@1: 0.592279 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.245823 Acc@1: 0.592628 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.244841 Acc@1: 0.579492 \n",
      "\tTrain Epoch: 64 \tLoss: 1.248924 Acc@1: 0.600700 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.249447 Acc@1: 0.593737 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.250405 Acc@1: 0.594153 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.344788 Acc@1: 0.576367 \n",
      "\tTrain Epoch: 65 \tLoss: 1.272595 Acc@1: 0.603803 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.182876 Acc@1: 0.609662 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.204542 Acc@1: 0.607831 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.262779 Acc@1: 0.586133 \n",
      "\tTrain Epoch: 66 \tLoss: 1.267162 Acc@1: 0.589855 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.217655 Acc@1: 0.601231 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.187964 Acc@1: 0.609874 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.218651 Acc@1: 0.598047 \n",
      "\tTrain Epoch: 67 \tLoss: 1.201176 Acc@1: 0.623337 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.243596 Acc@1: 0.610377 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.260446 Acc@1: 0.604335 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.267892 Acc@1: 0.601855 \n",
      "\tTrain Epoch: 68 \tLoss: 1.283494 Acc@1: 0.597396 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 1.189325 Acc@1: 0.612462 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 1.184663 Acc@1: 0.610768 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.206819 Acc@1: 0.602441 \n",
      "\tTrain Epoch: 69 \tLoss: 1.156057 Acc@1: 0.622122 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.176259 Acc@1: 0.621348 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.178921 Acc@1: 0.620649 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.276542 Acc@1: 0.591895 \n",
      "\tTrain Epoch: 70 \tLoss: 1.210680 Acc@1: 0.614922 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.224650 Acc@1: 0.611986 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.200473 Acc@1: 0.614287 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.229018 Acc@1: 0.595508 \n",
      "\tTrain Epoch: 71 \tLoss: 1.167756 Acc@1: 0.607708 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.199065 Acc@1: 0.618575 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.188062 Acc@1: 0.619303 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.287309 Acc@1: 0.579297 \n",
      "\tTrain Epoch: 72 \tLoss: 1.247284 Acc@1: 0.598592 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.198142 Acc@1: 0.605127 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.223165 Acc@1: 0.603315 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.210164 Acc@1: 0.602637 \n",
      "\tTrain Epoch: 73 \tLoss: 1.123651 Acc@1: 0.625636 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.188673 Acc@1: 0.616928 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.199864 Acc@1: 0.612626 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.200223 Acc@1: 0.605078 \n",
      "\tTrain Epoch: 74 \tLoss: 1.219212 Acc@1: 0.607900 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.191982 Acc@1: 0.612740 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.189616 Acc@1: 0.616243 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.157591 Acc@1: 0.615625 \n",
      "\tTrain Epoch: 75 \tLoss: 1.133612 Acc@1: 0.616522 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.176803 Acc@1: 0.615523 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.178675 Acc@1: 0.618947 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.141470 Acc@1: 0.608301 \n",
      "\tTrain Epoch: 76 \tLoss: 1.117103 Acc@1: 0.636000 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.124977 Acc@1: 0.626890 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.163874 Acc@1: 0.619572 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.241884 Acc@1: 0.604395 \n",
      "\tTrain Epoch: 77 \tLoss: 1.202565 Acc@1: 0.611083 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 1.153377 Acc@1: 0.623298 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 1.173502 Acc@1: 0.621518 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.211499 Acc@1: 0.616406 \n",
      "\tTrain Epoch: 78 \tLoss: 1.153134 Acc@1: 0.629268 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.167637 Acc@1: 0.620687 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.170028 Acc@1: 0.621779 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.188955 Acc@1: 0.608301 \n",
      "\tTrain Epoch: 79 \tLoss: 1.182511 Acc@1: 0.612285 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.171632 Acc@1: 0.620260 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.171196 Acc@1: 0.618996 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 1.212003 Acc@1: 0.610938 \n",
      "\tTrain Epoch: 80 \tLoss: 1.209242 Acc@1: 0.614500 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.178536 Acc@1: 0.622864 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.149602 Acc@1: 0.626842 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.156758 Acc@1: 0.619043 \n",
      "\tTrain Epoch: 81 \tLoss: 1.093888 Acc@1: 0.633572 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.138815 Acc@1: 0.630431 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.138862 Acc@1: 0.630607 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.248619 Acc@1: 0.613672 \n",
      "\tTrain Epoch: 82 \tLoss: 1.183869 Acc@1: 0.623582 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.168243 Acc@1: 0.629641 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.179146 Acc@1: 0.625036 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.326184 Acc@1: 0.588574 \n",
      "\tTrain Epoch: 83 \tLoss: 1.205442 Acc@1: 0.606574 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.200455 Acc@1: 0.607030 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.204172 Acc@1: 0.608222 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.176149 Acc@1: 0.603711 \n",
      "\tTrain Epoch: 84 \tLoss: 1.181935 Acc@1: 0.594335 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 1.135612 Acc@1: 0.618412 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 1.127746 Acc@1: 0.623047 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.149682 Acc@1: 0.620605 \n",
      "\tTrain Epoch: 85 \tLoss: 1.139115 Acc@1: 0.632323 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.100663 Acc@1: 0.636305 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.102819 Acc@1: 0.638902 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.136723 Acc@1: 0.629297 \n",
      "\tTrain Epoch: 86 \tLoss: 1.118855 Acc@1: 0.646817 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 1.123524 Acc@1: 0.637888 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 1.123642 Acc@1: 0.635483 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.133582 Acc@1: 0.628809 \n",
      "\tTrain Epoch: 87 \tLoss: 1.125441 Acc@1: 0.630424 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.099525 Acc@1: 0.642886 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.106072 Acc@1: 0.641028 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.170902 Acc@1: 0.619629 \n",
      "\tTrain Epoch: 88 \tLoss: 1.172493 Acc@1: 0.627596 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 1.101673 Acc@1: 0.637255 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 1.082483 Acc@1: 0.644724 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.086633 Acc@1: 0.635449 \n",
      "\tTrain Epoch: 89 \tLoss: 1.038671 Acc@1: 0.650664 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.080422 Acc@1: 0.643046 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.088129 Acc@1: 0.647845 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.151253 Acc@1: 0.624414 \n",
      "\tTrain Epoch: 90 \tLoss: 1.144566 Acc@1: 0.639900 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 1.127313 Acc@1: 0.643910 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 1.122474 Acc@1: 0.644147 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 22:00:47:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 22:00:47:INFO:{'accuracy': 0.64169921875, 'accuracy_per_epoch': [0.156640625, 0.2849609375, 0.30400390625, 0.3255859375, 0.35966796875, 0.35458984375, 0.3912109375, 0.396875, 0.38681640625, 0.4048828125, 0.41181640625, 0.40458984375, 0.42333984375, 0.40380859375, 0.447265625, 0.4302734375, 0.43681640625, 0.46396484375, 0.4533203125, 0.46171875, 0.42822265625, 0.450390625, 0.46103515625, 0.4576171875, 0.48291015625, 0.4869140625, 0.5009765625, 0.491796875, 0.50732421875, 0.524609375, 0.51953125, 0.50087890625, 0.5224609375, 0.52587890625, 0.52294921875, 0.5345703125, 0.52255859375, 0.535546875, 0.5365234375, 0.5328125, 0.52109375, 0.52734375, 0.537890625, 0.5419921875, 0.554296875, 0.5451171875, 0.56455078125, 0.54775390625, 0.566015625, 0.5572265625, 0.55634765625, 0.56689453125, 0.58330078125, 0.59208984375, 0.58095703125, 0.58251953125, 0.59560546875, 0.59130859375, 0.58837890625, 0.58955078125, 0.583203125, 0.58544921875, 0.5794921875, 0.5763671875, 0.5861328125, 0.598046875, 0.60185546875, 0.60244140625, 0.59189453125, 0.5955078125, 0.579296875, 0.60263671875, 0.605078125, 0.615625, 0.60830078125, 0.60439453125, 0.61640625, 0.60830078125, 0.6109375, 0.61904296875, 0.613671875, 0.58857421875, 0.6037109375, 0.62060546875, 0.629296875, 0.62880859375, 0.61962890625, 0.63544921875, 0.6244140625, 0.64169921875], 'avg_time_per_epoch_str': '0:00:08', 'time_per_epoch': [12.026652, 8.951723, 8.956742, 8.99453, 8.922498, 8.948346, 8.861182, 8.933114, 9.013382, 9.030871, 9.050951, 9.034394, 9.018528, 8.911836, 8.998257, 8.914082, 8.904411, 8.859717, 8.877743, 8.833979, 8.868005, 8.809808, 8.924682, 8.885957, 8.975755, 8.967231, 8.806179, 8.778106, 8.917807, 8.882961, 8.904662, 8.792496, 8.841238, 8.897927, 8.933712, 8.840988, 8.849304, 8.885806, 8.956857, 8.934359, 8.899406, 8.946591, 8.871386, 8.91475, 8.806915, 9.022003, 8.940138, 9.023848, 8.858369, 8.856438, 8.887144, 8.905317, 8.886071, 8.897975, 8.73515, 8.884277, 8.895346, 8.748495, 8.834759, 8.828806, 8.865912, 8.797348, 8.861014, 8.802707, 8.891094, 8.95709, 8.802127, 8.882322, 8.784438, 8.813681, 8.877342, 8.861187, 8.857888, 8.896817, 8.764672, 8.903551, 8.858954, 8.997993, 8.879918, 8.90108, 8.766847, 8.984442, 8.963815, 8.965187, 8.792635, 8.774975, 8.933287, 8.927477, 8.803286, 8.83019]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.140725 Acc@1: 0.641699 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='BinMech',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(5) We test the learning effectiveness for Private learning for Opacus-DPCR with **FDA model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **FDA** achieves:\n",
    "Accuracy of **41.5%** and Loss of **1.58** after private training.\n",
    "Best Accuracy of **42.5%** and best Loss of **1.57** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with FDA...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 3.055033 Acc@1: 0.115564 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 4.829570 Acc@1: 0.120851 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 4.085608 Acc@1: 0.118555 \n",
      "\tTrain Epoch: 2 \tLoss: 3.988531 Acc@1: 0.126080 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 3.263390 Acc@1: 0.123855 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.850712 Acc@1: 0.119172 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.399296 Acc@1: 0.138184 \n",
      "\tTrain Epoch: 3 \tLoss: 2.373634 Acc@1: 0.141026 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.378890 Acc@1: 0.142575 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.353717 Acc@1: 0.133084 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 2.299743 Acc@1: 0.117773 \n",
      "\tTrain Epoch: 4 \tLoss: 2.307395 Acc@1: 0.113479 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.311182 Acc@1: 0.119193 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 2.326636 Acc@1: 0.125253 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 2.290624 Acc@1: 0.153711 \n",
      "\tTrain Epoch: 5 \tLoss: 2.275866 Acc@1: 0.152284 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 2.284042 Acc@1: 0.165054 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 2.292663 Acc@1: 0.169851 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 2.491129 Acc@1: 0.185742 \n",
      "\tTrain Epoch: 6 \tLoss: 2.479416 Acc@1: 0.193644 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 2.350739 Acc@1: 0.152652 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 2.338022 Acc@1: 0.133922 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 2.296394 Acc@1: 0.157910 \n",
      "\tTrain Epoch: 7 \tLoss: 2.279917 Acc@1: 0.153647 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 2.250832 Acc@1: 0.159373 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 2.267729 Acc@1: 0.166577 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 2.458615 Acc@1: 0.172266 \n",
      "\tTrain Epoch: 8 \tLoss: 2.512266 Acc@1: 0.178589 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 2.355591 Acc@1: 0.177624 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 2.328946 Acc@1: 0.180460 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 2.291089 Acc@1: 0.179004 \n",
      "\tTrain Epoch: 9 \tLoss: 2.341938 Acc@1: 0.175289 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 2.290687 Acc@1: 0.175786 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 2.253507 Acc@1: 0.178565 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 2.182282 Acc@1: 0.163965 \n",
      "\tTrain Epoch: 10 \tLoss: 2.179503 Acc@1: 0.176412 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.352438 Acc@1: 0.193992 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 2.264506 Acc@1: 0.204786 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 2.068642 Acc@1: 0.209473 \n",
      "\tTrain Epoch: 11 \tLoss: 2.033115 Acc@1: 0.224490 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.110380 Acc@1: 0.211146 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 2.157174 Acc@1: 0.199843 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 2.293991 Acc@1: 0.205762 \n",
      "\tTrain Epoch: 12 \tLoss: 2.319785 Acc@1: 0.183277 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.248078 Acc@1: 0.197576 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 2.184331 Acc@1: 0.200746 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 2.135379 Acc@1: 0.191895 \n",
      "\tTrain Epoch: 13 \tLoss: 2.138904 Acc@1: 0.199093 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.154849 Acc@1: 0.203327 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 2.156106 Acc@1: 0.197536 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.319212 Acc@1: 0.199121 \n",
      "\tTrain Epoch: 14 \tLoss: 2.318038 Acc@1: 0.198718 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.191769 Acc@1: 0.196818 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 2.145591 Acc@1: 0.198763 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 2.091404 Acc@1: 0.228418 \n",
      "\tTrain Epoch: 15 \tLoss: 2.106157 Acc@1: 0.220330 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.065722 Acc@1: 0.232175 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 2.075361 Acc@1: 0.233032 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 1.998341 Acc@1: 0.232422 \n",
      "\tTrain Epoch: 16 \tLoss: 2.000897 Acc@1: 0.226069 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.043793 Acc@1: 0.230103 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 2.051933 Acc@1: 0.221815 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.013934 Acc@1: 0.226074 \n",
      "\tTrain Epoch: 17 \tLoss: 2.050730 Acc@1: 0.225641 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.045110 Acc@1: 0.223274 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 2.033872 Acc@1: 0.230446 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 2.020739 Acc@1: 0.252344 \n",
      "\tTrain Epoch: 18 \tLoss: 2.047354 Acc@1: 0.255169 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.052453 Acc@1: 0.242155 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 2.044817 Acc@1: 0.238685 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.036054 Acc@1: 0.249121 \n",
      "\tTrain Epoch: 19 \tLoss: 2.023574 Acc@1: 0.252806 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.005720 Acc@1: 0.259767 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 2.020644 Acc@1: 0.257470 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 2.010883 Acc@1: 0.245605 \n",
      "\tTrain Epoch: 20 \tLoss: 1.971926 Acc@1: 0.236661 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 2.007023 Acc@1: 0.240970 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.994691 Acc@1: 0.243430 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.064787 Acc@1: 0.261816 \n",
      "\tTrain Epoch: 21 \tLoss: 2.036958 Acc@1: 0.251969 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.980699 Acc@1: 0.260442 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 2.023228 Acc@1: 0.252078 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.085512 Acc@1: 0.201172 \n",
      "\tTrain Epoch: 22 \tLoss: 2.086211 Acc@1: 0.186270 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.198727 Acc@1: 0.200262 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 2.152816 Acc@1: 0.199122 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 2.241488 Acc@1: 0.155762 \n",
      "\tTrain Epoch: 23 \tLoss: 2.203371 Acc@1: 0.166829 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.192294 Acc@1: 0.184814 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 2.164869 Acc@1: 0.194060 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.171769 Acc@1: 0.200488 \n",
      "\tTrain Epoch: 24 \tLoss: 2.151183 Acc@1: 0.201958 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.127123 Acc@1: 0.198688 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 2.121682 Acc@1: 0.212245 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.022082 Acc@1: 0.226660 \n",
      "\tTrain Epoch: 25 \tLoss: 1.991334 Acc@1: 0.229564 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.015370 Acc@1: 0.231925 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 2.043397 Acc@1: 0.230361 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 2.075902 Acc@1: 0.248438 \n",
      "\tTrain Epoch: 26 \tLoss: 2.052301 Acc@1: 0.258448 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.032272 Acc@1: 0.241779 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 2.024211 Acc@1: 0.240985 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 2.016031 Acc@1: 0.242871 \n",
      "\tTrain Epoch: 27 \tLoss: 2.039780 Acc@1: 0.242175 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.050483 Acc@1: 0.235709 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 2.044467 Acc@1: 0.240439 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.962284 Acc@1: 0.250684 \n",
      "\tTrain Epoch: 28 \tLoss: 1.950852 Acc@1: 0.242286 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.981745 Acc@1: 0.250515 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.980648 Acc@1: 0.254671 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.920532 Acc@1: 0.275000 \n",
      "\tTrain Epoch: 29 \tLoss: 1.964078 Acc@1: 0.268159 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.965579 Acc@1: 0.274994 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.969034 Acc@1: 0.273309 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.950547 Acc@1: 0.273535 \n",
      "\tTrain Epoch: 30 \tLoss: 1.953010 Acc@1: 0.259052 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 2.032514 Acc@1: 0.263193 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.991419 Acc@1: 0.270535 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.988758 Acc@1: 0.274902 \n",
      "\tTrain Epoch: 31 \tLoss: 1.992957 Acc@1: 0.291165 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.921533 Acc@1: 0.289817 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.913976 Acc@1: 0.289011 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.976169 Acc@1: 0.263379 \n",
      "\tTrain Epoch: 32 \tLoss: 1.968053 Acc@1: 0.260978 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.926503 Acc@1: 0.280055 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.974842 Acc@1: 0.268099 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.944801 Acc@1: 0.285938 \n",
      "\tTrain Epoch: 33 \tLoss: 1.931050 Acc@1: 0.300518 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.969599 Acc@1: 0.269506 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.976728 Acc@1: 0.266105 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.927509 Acc@1: 0.278516 \n",
      "\tTrain Epoch: 34 \tLoss: 1.922644 Acc@1: 0.284884 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.917384 Acc@1: 0.293034 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.936802 Acc@1: 0.281153 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 2.008237 Acc@1: 0.256348 \n",
      "\tTrain Epoch: 35 \tLoss: 1.994347 Acc@1: 0.242528 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.967810 Acc@1: 0.272884 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.937815 Acc@1: 0.279304 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.885742 Acc@1: 0.285449 \n",
      "\tTrain Epoch: 36 \tLoss: 1.910948 Acc@1: 0.269981 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.887617 Acc@1: 0.290047 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.874606 Acc@1: 0.304067 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.958123 Acc@1: 0.312207 \n",
      "\tTrain Epoch: 37 \tLoss: 1.938698 Acc@1: 0.300199 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.903088 Acc@1: 0.298811 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.878285 Acc@1: 0.302842 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.858346 Acc@1: 0.312402 \n",
      "\tTrain Epoch: 38 \tLoss: 1.811781 Acc@1: 0.316286 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.843538 Acc@1: 0.303549 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.864416 Acc@1: 0.303973 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.902304 Acc@1: 0.301465 \n",
      "\tTrain Epoch: 39 \tLoss: 1.905235 Acc@1: 0.293046 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.879870 Acc@1: 0.306984 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.870595 Acc@1: 0.306188 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.869437 Acc@1: 0.325098 \n",
      "\tTrain Epoch: 40 \tLoss: 1.869666 Acc@1: 0.322294 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.843776 Acc@1: 0.323736 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.832254 Acc@1: 0.328342 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.860536 Acc@1: 0.295312 \n",
      "\tTrain Epoch: 41 \tLoss: 1.844836 Acc@1: 0.307769 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.810618 Acc@1: 0.337084 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.796132 Acc@1: 0.344668 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.766776 Acc@1: 0.340332 \n",
      "\tTrain Epoch: 42 \tLoss: 1.787845 Acc@1: 0.333979 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.985239 Acc@1: 0.268738 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 2.060354 Acc@1: 0.249677 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 2.243640 Acc@1: 0.242285 \n",
      "\tTrain Epoch: 43 \tLoss: 2.213074 Acc@1: 0.247934 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.084590 Acc@1: 0.231714 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 2.062298 Acc@1: 0.228915 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.979711 Acc@1: 0.262109 \n",
      "\tTrain Epoch: 44 \tLoss: 1.970955 Acc@1: 0.253937 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.999518 Acc@1: 0.260460 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.982388 Acc@1: 0.264007 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.897230 Acc@1: 0.288281 \n",
      "\tTrain Epoch: 45 \tLoss: 1.856821 Acc@1: 0.298916 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.900663 Acc@1: 0.281406 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.902904 Acc@1: 0.285630 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.875733 Acc@1: 0.293652 \n",
      "\tTrain Epoch: 46 \tLoss: 1.889596 Acc@1: 0.296774 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.909683 Acc@1: 0.299777 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.894006 Acc@1: 0.302767 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.869334 Acc@1: 0.314355 \n",
      "\tTrain Epoch: 47 \tLoss: 1.898608 Acc@1: 0.307844 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.887839 Acc@1: 0.294880 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.905686 Acc@1: 0.291666 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.998674 Acc@1: 0.264258 \n",
      "\tTrain Epoch: 48 \tLoss: 1.972313 Acc@1: 0.271329 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.943866 Acc@1: 0.272693 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.944104 Acc@1: 0.274080 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.917854 Acc@1: 0.297168 \n",
      "\tTrain Epoch: 49 \tLoss: 1.944872 Acc@1: 0.277233 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.875635 Acc@1: 0.303553 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.867610 Acc@1: 0.301612 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.823564 Acc@1: 0.306445 \n",
      "\tTrain Epoch: 50 \tLoss: 1.796928 Acc@1: 0.321550 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.832210 Acc@1: 0.313591 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.843290 Acc@1: 0.315165 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.828317 Acc@1: 0.322949 \n",
      "\tTrain Epoch: 51 \tLoss: 1.810352 Acc@1: 0.318654 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.784660 Acc@1: 0.327686 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.782176 Acc@1: 0.336258 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.801626 Acc@1: 0.351855 \n",
      "\tTrain Epoch: 52 \tLoss: 1.777315 Acc@1: 0.363455 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.756385 Acc@1: 0.354486 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.779841 Acc@1: 0.340840 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.859458 Acc@1: 0.284473 \n",
      "\tTrain Epoch: 53 \tLoss: 1.860152 Acc@1: 0.273657 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.886248 Acc@1: 0.297885 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.870087 Acc@1: 0.303125 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.869527 Acc@1: 0.283008 \n",
      "\tTrain Epoch: 54 \tLoss: 1.888513 Acc@1: 0.281189 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.861458 Acc@1: 0.304606 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.867648 Acc@1: 0.310506 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.804282 Acc@1: 0.320605 \n",
      "\tTrain Epoch: 55 \tLoss: 1.802460 Acc@1: 0.328172 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.847812 Acc@1: 0.320542 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.832119 Acc@1: 0.324857 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.883565 Acc@1: 0.328027 \n",
      "\tTrain Epoch: 56 \tLoss: 1.841303 Acc@1: 0.310970 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.809578 Acc@1: 0.320005 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.805522 Acc@1: 0.327362 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.787751 Acc@1: 0.344434 \n",
      "\tTrain Epoch: 57 \tLoss: 1.785564 Acc@1: 0.359684 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.787926 Acc@1: 0.338214 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.768873 Acc@1: 0.348728 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.767710 Acc@1: 0.319727 \n",
      "\tTrain Epoch: 58 \tLoss: 1.752843 Acc@1: 0.328313 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.742898 Acc@1: 0.341370 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.740616 Acc@1: 0.348507 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.775046 Acc@1: 0.344531 \n",
      "\tTrain Epoch: 59 \tLoss: 1.766653 Acc@1: 0.351053 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.785384 Acc@1: 0.345329 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.786323 Acc@1: 0.345747 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.774681 Acc@1: 0.342187 \n",
      "\tTrain Epoch: 60 \tLoss: 1.764286 Acc@1: 0.350282 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.794550 Acc@1: 0.347428 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.761480 Acc@1: 0.352420 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.722875 Acc@1: 0.359863 \n",
      "\tTrain Epoch: 61 \tLoss: 1.719434 Acc@1: 0.356955 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.718495 Acc@1: 0.370109 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.711886 Acc@1: 0.371655 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.704077 Acc@1: 0.367969 \n",
      "\tTrain Epoch: 62 \tLoss: 1.704006 Acc@1: 0.357548 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.672734 Acc@1: 0.383947 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.697550 Acc@1: 0.370977 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.838061 Acc@1: 0.315039 \n",
      "\tTrain Epoch: 63 \tLoss: 1.861622 Acc@1: 0.324540 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.820751 Acc@1: 0.331257 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.834207 Acc@1: 0.327946 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.816480 Acc@1: 0.342969 \n",
      "\tTrain Epoch: 64 \tLoss: 1.851851 Acc@1: 0.312844 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.772354 Acc@1: 0.336329 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.776859 Acc@1: 0.341246 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.740282 Acc@1: 0.356836 \n",
      "\tTrain Epoch: 65 \tLoss: 1.744123 Acc@1: 0.344810 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.769027 Acc@1: 0.348106 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.780082 Acc@1: 0.337341 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.802655 Acc@1: 0.339746 \n",
      "\tTrain Epoch: 66 \tLoss: 1.768421 Acc@1: 0.364251 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.786558 Acc@1: 0.337532 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.769411 Acc@1: 0.341645 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.730730 Acc@1: 0.348730 \n",
      "\tTrain Epoch: 67 \tLoss: 1.687866 Acc@1: 0.343910 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.728004 Acc@1: 0.359849 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.727463 Acc@1: 0.357490 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.782078 Acc@1: 0.335352 \n",
      "\tTrain Epoch: 68 \tLoss: 1.771982 Acc@1: 0.324987 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 1.723840 Acc@1: 0.346470 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 1.733951 Acc@1: 0.346398 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.712171 Acc@1: 0.352246 \n",
      "\tTrain Epoch: 69 \tLoss: 1.694654 Acc@1: 0.361862 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.708393 Acc@1: 0.368729 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.708436 Acc@1: 0.368123 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.710369 Acc@1: 0.360254 \n",
      "\tTrain Epoch: 70 \tLoss: 1.749317 Acc@1: 0.353030 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.722659 Acc@1: 0.363672 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.716997 Acc@1: 0.367385 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.685058 Acc@1: 0.366992 \n",
      "\tTrain Epoch: 71 \tLoss: 1.628528 Acc@1: 0.387352 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.676550 Acc@1: 0.379843 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.673794 Acc@1: 0.377836 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.719831 Acc@1: 0.371289 \n",
      "\tTrain Epoch: 72 \tLoss: 1.699941 Acc@1: 0.393863 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.672184 Acc@1: 0.396077 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.669959 Acc@1: 0.390414 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.737615 Acc@1: 0.365137 \n",
      "\tTrain Epoch: 73 \tLoss: 1.672601 Acc@1: 0.381485 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.729087 Acc@1: 0.359768 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.746538 Acc@1: 0.359929 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.786825 Acc@1: 0.359375 \n",
      "\tTrain Epoch: 74 \tLoss: 1.835015 Acc@1: 0.361753 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.749091 Acc@1: 0.359253 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.736102 Acc@1: 0.358300 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.749604 Acc@1: 0.357324 \n",
      "\tTrain Epoch: 75 \tLoss: 1.740538 Acc@1: 0.360020 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.694987 Acc@1: 0.377956 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.685532 Acc@1: 0.377858 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.671569 Acc@1: 0.396680 \n",
      "\tTrain Epoch: 76 \tLoss: 1.641890 Acc@1: 0.396500 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.671710 Acc@1: 0.387564 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.653498 Acc@1: 0.391241 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.653576 Acc@1: 0.385059 \n",
      "\tTrain Epoch: 77 \tLoss: 1.679836 Acc@1: 0.378241 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 1.654099 Acc@1: 0.390724 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 1.634901 Acc@1: 0.397865 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.673894 Acc@1: 0.399023 \n",
      "\tTrain Epoch: 78 \tLoss: 1.662508 Acc@1: 0.398049 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.688519 Acc@1: 0.396156 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.666889 Acc@1: 0.395294 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.674797 Acc@1: 0.387500 \n",
      "\tTrain Epoch: 79 \tLoss: 1.703073 Acc@1: 0.369533 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.655617 Acc@1: 0.396521 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.657069 Acc@1: 0.392570 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 1.636504 Acc@1: 0.387988 \n",
      "\tTrain Epoch: 80 \tLoss: 1.640022 Acc@1: 0.397500 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.617409 Acc@1: 0.409505 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.611338 Acc@1: 0.412031 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.624144 Acc@1: 0.400195 \n",
      "\tTrain Epoch: 81 \tLoss: 1.617837 Acc@1: 0.409417 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.606655 Acc@1: 0.409129 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.610764 Acc@1: 0.409858 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.597409 Acc@1: 0.406152 \n",
      "\tTrain Epoch: 82 \tLoss: 1.605571 Acc@1: 0.401579 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.603216 Acc@1: 0.416992 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 1.585263 Acc@1: 0.420563 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.637305 Acc@1: 0.401660 \n",
      "\tTrain Epoch: 83 \tLoss: 1.607308 Acc@1: 0.437749 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.668549 Acc@1: 0.403494 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.694334 Acc@1: 0.403112 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.768533 Acc@1: 0.379004 \n",
      "\tTrain Epoch: 84 \tLoss: 1.820093 Acc@1: 0.360142 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 1.713652 Acc@1: 0.387716 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 1.701817 Acc@1: 0.386578 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.717267 Acc@1: 0.393066 \n",
      "\tTrain Epoch: 85 \tLoss: 1.730501 Acc@1: 0.390909 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.691237 Acc@1: 0.400655 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.665101 Acc@1: 0.402572 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.701905 Acc@1: 0.372070 \n",
      "\tTrain Epoch: 86 \tLoss: 1.688228 Acc@1: 0.390144 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 1.666601 Acc@1: 0.402355 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 1.665494 Acc@1: 0.402699 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.604543 Acc@1: 0.414941 \n",
      "\tTrain Epoch: 87 \tLoss: 1.568191 Acc@1: 0.434913 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.600754 Acc@1: 0.425921 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.607604 Acc@1: 0.421192 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.567895 Acc@1: 0.424805 \n",
      "\tTrain Epoch: 88 \tLoss: 1.588746 Acc@1: 0.425473 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 1.614129 Acc@1: 0.422183 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 1.625096 Acc@1: 0.420357 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.652463 Acc@1: 0.404883 \n",
      "\tTrain Epoch: 89 \tLoss: 1.644870 Acc@1: 0.413177 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.647216 Acc@1: 0.406542 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.640926 Acc@1: 0.412272 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.594653 Acc@1: 0.415430 \n",
      "\tTrain Epoch: 90 \tLoss: 1.578232 Acc@1: 0.421446 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 1.582767 Acc@1: 0.430795 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 1.580874 Acc@1: 0.431887 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 22:19:10:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 22:19:10:INFO:{'accuracy': 0.4248046875, 'accuracy_per_epoch': [0.1185546875, 0.13818359375, 0.1177734375, 0.1537109375, 0.1857421875, 0.15791015625, 0.172265625, 0.17900390625, 0.16396484375, 0.20947265625, 0.20576171875, 0.19189453125, 0.19912109375, 0.22841796875, 0.232421875, 0.22607421875, 0.25234375, 0.24912109375, 0.24560546875, 0.26181640625, 0.201171875, 0.15576171875, 0.20048828125, 0.22666015625, 0.2484375, 0.24287109375, 0.25068359375, 0.275, 0.27353515625, 0.27490234375, 0.26337890625, 0.2859375, 0.278515625, 0.25634765625, 0.28544921875, 0.31220703125, 0.31240234375, 0.30146484375, 0.32509765625, 0.2953125, 0.34033203125, 0.24228515625, 0.262109375, 0.28828125, 0.29365234375, 0.31435546875, 0.2642578125, 0.29716796875, 0.3064453125, 0.32294921875, 0.35185546875, 0.28447265625, 0.2830078125, 0.32060546875, 0.32802734375, 0.34443359375, 0.3197265625, 0.34453125, 0.3421875, 0.35986328125, 0.36796875, 0.3150390625, 0.34296875, 0.3568359375, 0.33974609375, 0.34873046875, 0.3353515625, 0.35224609375, 0.36025390625, 0.3669921875, 0.3712890625, 0.36513671875, 0.359375, 0.35732421875, 0.3966796875, 0.38505859375, 0.3990234375, 0.3875, 0.38798828125, 0.4001953125, 0.40615234375, 0.40166015625, 0.37900390625, 0.39306640625, 0.3720703125, 0.41494140625, 0.4248046875, 0.4048828125, 0.4154296875, 0.41474609375], 'avg_time_per_epoch_str': '0:00:08', 'time_per_epoch': [11.878322, 9.031778, 8.837687, 8.941907, 8.917581, 8.994905, 8.907682, 8.966938, 9.019332, 9.15392, 9.082783, 8.980518, 9.000132, 9.058846, 8.999273, 9.090624, 8.87509, 9.004966, 8.962568, 8.970565, 8.958881, 8.862323, 8.962979, 8.787201, 9.075518, 9.024414, 8.945374, 8.897749, 8.879308, 8.920514, 8.862407, 8.92499, 8.931096, 8.883961, 8.949656, 8.905149, 8.952952, 8.916833, 8.937748, 8.941147, 8.838873, 8.955954, 8.929532, 8.911431, 8.875402, 8.907378, 8.946031, 9.008757, 8.95783, 8.970153, 8.830648, 8.822229, 8.918672, 8.88562, 8.826206, 8.952636, 9.046701, 8.961846, 8.956486, 8.906862, 8.851076, 8.87589, 8.92658, 8.799344, 8.887771, 8.870896, 8.808234, 8.917523, 8.835276, 8.731103, 8.854506, 8.879682, 8.832313, 8.938912, 8.793318, 8.718076, 8.794321, 8.940847, 8.892579, 8.977569, 8.961604, 8.841781, 8.95462, 8.746477, 8.855566, 8.800624, 8.940396, 8.907645, 8.808443, 8.811374]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.579677 Acc@1: 0.414746 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='FDA',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(6) We test the learning effectiveness for Private learning for Opacus-DPCR with **BCRG model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **BCRG** achieves:\n",
    "Accuracy of **66.0%** and Loss of **1.15** after private training.\n",
    "Best Accuracy of **67.6%** and best Loss of **1.03** during private training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with BCRG...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.302180 Acc@1: 0.103614 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.278556 Acc@1: 0.130260 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.094152 Acc@1: 0.196289 \n",
      "\tTrain Epoch: 2 \tLoss: 2.117044 Acc@1: 0.193696 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.172542 Acc@1: 0.217261 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.144383 Acc@1: 0.220747 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.035154 Acc@1: 0.259082 \n",
      "\tTrain Epoch: 3 \tLoss: 2.028397 Acc@1: 0.257436 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 2.011293 Acc@1: 0.273426 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.970845 Acc@1: 0.285193 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 1.950523 Acc@1: 0.315625 \n",
      "\tTrain Epoch: 4 \tLoss: 1.992143 Acc@1: 0.300793 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.968584 Acc@1: 0.300054 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.937467 Acc@1: 0.309002 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.904313 Acc@1: 0.331836 \n",
      "\tTrain Epoch: 5 \tLoss: 1.900794 Acc@1: 0.332487 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.843272 Acc@1: 0.346347 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.845127 Acc@1: 0.348950 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.800639 Acc@1: 0.366699 \n",
      "\tTrain Epoch: 6 \tLoss: 1.801889 Acc@1: 0.367428 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.765061 Acc@1: 0.364801 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.777225 Acc@1: 0.357380 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.815185 Acc@1: 0.379883 \n",
      "\tTrain Epoch: 7 \tLoss: 1.781228 Acc@1: 0.372995 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.796034 Acc@1: 0.371639 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.790692 Acc@1: 0.378780 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 1.821280 Acc@1: 0.381445 \n",
      "\tTrain Epoch: 8 \tLoss: 1.800668 Acc@1: 0.362181 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.777612 Acc@1: 0.382050 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.765453 Acc@1: 0.388889 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 1.713119 Acc@1: 0.405859 \n",
      "\tTrain Epoch: 9 \tLoss: 1.720641 Acc@1: 0.419387 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.732677 Acc@1: 0.396909 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.740734 Acc@1: 0.395539 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.738490 Acc@1: 0.399121 \n",
      "\tTrain Epoch: 10 \tLoss: 1.732254 Acc@1: 0.396432 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.690075 Acc@1: 0.414146 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.666326 Acc@1: 0.419663 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 1.596990 Acc@1: 0.438086 \n",
      "\tTrain Epoch: 11 \tLoss: 1.598395 Acc@1: 0.437531 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.633261 Acc@1: 0.433693 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.626574 Acc@1: 0.425595 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 1.647665 Acc@1: 0.430859 \n",
      "\tTrain Epoch: 12 \tLoss: 1.661456 Acc@1: 0.415654 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.682217 Acc@1: 0.416315 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.666612 Acc@1: 0.419877 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 1.679824 Acc@1: 0.431250 \n",
      "\tTrain Epoch: 13 \tLoss: 1.673070 Acc@1: 0.443548 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.651184 Acc@1: 0.430484 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.658809 Acc@1: 0.432235 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.614221 Acc@1: 0.434863 \n",
      "\tTrain Epoch: 14 \tLoss: 1.584958 Acc@1: 0.438363 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.637199 Acc@1: 0.432076 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.619862 Acc@1: 0.438917 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.610194 Acc@1: 0.455176 \n",
      "\tTrain Epoch: 15 \tLoss: 1.616822 Acc@1: 0.462193 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.580603 Acc@1: 0.467737 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.588872 Acc@1: 0.466825 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 1.571448 Acc@1: 0.452344 \n",
      "\tTrain Epoch: 16 \tLoss: 1.536322 Acc@1: 0.462831 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.551943 Acc@1: 0.462370 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.553458 Acc@1: 0.468186 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.501662 Acc@1: 0.474609 \n",
      "\tTrain Epoch: 17 \tLoss: 1.577047 Acc@1: 0.454872 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.572977 Acc@1: 0.464827 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.568542 Acc@1: 0.469984 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.489568 Acc@1: 0.477832 \n",
      "\tTrain Epoch: 18 \tLoss: 1.490092 Acc@1: 0.480585 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.514991 Acc@1: 0.481011 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.509637 Acc@1: 0.482433 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.521754 Acc@1: 0.495020 \n",
      "\tTrain Epoch: 19 \tLoss: 1.516638 Acc@1: 0.497804 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.509719 Acc@1: 0.495031 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.520183 Acc@1: 0.493074 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.498222 Acc@1: 0.491406 \n",
      "\tTrain Epoch: 20 \tLoss: 1.538073 Acc@1: 0.479134 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.484247 Acc@1: 0.498609 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.484769 Acc@1: 0.501399 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.450586 Acc@1: 0.516211 \n",
      "\tTrain Epoch: 21 \tLoss: 1.425813 Acc@1: 0.520669 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.469390 Acc@1: 0.508624 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.477654 Acc@1: 0.502339 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.571474 Acc@1: 0.479102 \n",
      "\tTrain Epoch: 22 \tLoss: 1.606140 Acc@1: 0.475517 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.554511 Acc@1: 0.475423 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.551786 Acc@1: 0.478248 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.558170 Acc@1: 0.476074 \n",
      "\tTrain Epoch: 23 \tLoss: 1.541456 Acc@1: 0.471220 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.521266 Acc@1: 0.482398 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.508954 Acc@1: 0.487984 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.517514 Acc@1: 0.492480 \n",
      "\tTrain Epoch: 24 \tLoss: 1.499279 Acc@1: 0.509016 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.530717 Acc@1: 0.501215 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.531076 Acc@1: 0.496833 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.462160 Acc@1: 0.501758 \n",
      "\tTrain Epoch: 25 \tLoss: 1.494679 Acc@1: 0.497797 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.445725 Acc@1: 0.513850 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.466719 Acc@1: 0.513547 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.483995 Acc@1: 0.509180 \n",
      "\tTrain Epoch: 26 \tLoss: 1.463234 Acc@1: 0.521656 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.462294 Acc@1: 0.519131 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.465191 Acc@1: 0.518965 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.468071 Acc@1: 0.513867 \n",
      "\tTrain Epoch: 27 \tLoss: 1.525637 Acc@1: 0.519241 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.438546 Acc@1: 0.521462 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.446988 Acc@1: 0.521749 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.377408 Acc@1: 0.521680 \n",
      "\tTrain Epoch: 28 \tLoss: 1.321011 Acc@1: 0.526555 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.431002 Acc@1: 0.524521 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.425318 Acc@1: 0.525821 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.401422 Acc@1: 0.529004 \n",
      "\tTrain Epoch: 29 \tLoss: 1.436589 Acc@1: 0.534328 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.393163 Acc@1: 0.537818 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.395666 Acc@1: 0.536775 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.358442 Acc@1: 0.541797 \n",
      "\tTrain Epoch: 30 \tLoss: 1.305195 Acc@1: 0.555329 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.387767 Acc@1: 0.547381 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.380215 Acc@1: 0.549495 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.362065 Acc@1: 0.534473 \n",
      "\tTrain Epoch: 31 \tLoss: 1.360422 Acc@1: 0.553715 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.353554 Acc@1: 0.551961 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.345787 Acc@1: 0.556583 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.402830 Acc@1: 0.543457 \n",
      "\tTrain Epoch: 32 \tLoss: 1.337795 Acc@1: 0.566367 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.372219 Acc@1: 0.552635 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.363147 Acc@1: 0.553404 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.369206 Acc@1: 0.554199 \n",
      "\tTrain Epoch: 33 \tLoss: 1.300223 Acc@1: 0.568912 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.338424 Acc@1: 0.554662 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.359254 Acc@1: 0.556056 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.400763 Acc@1: 0.541406 \n",
      "\tTrain Epoch: 34 \tLoss: 1.380788 Acc@1: 0.543605 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.371734 Acc@1: 0.552367 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.360422 Acc@1: 0.557173 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.377509 Acc@1: 0.545605 \n",
      "\tTrain Epoch: 35 \tLoss: 1.393908 Acc@1: 0.559040 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.377573 Acc@1: 0.555888 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.341330 Acc@1: 0.561491 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.349682 Acc@1: 0.563770 \n",
      "\tTrain Epoch: 36 \tLoss: 1.369037 Acc@1: 0.550682 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.305537 Acc@1: 0.577113 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.308063 Acc@1: 0.579403 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.322132 Acc@1: 0.558789 \n",
      "\tTrain Epoch: 37 \tLoss: 1.371983 Acc@1: 0.573062 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.312579 Acc@1: 0.579848 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.317923 Acc@1: 0.577276 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.328999 Acc@1: 0.559277 \n",
      "\tTrain Epoch: 38 \tLoss: 1.272131 Acc@1: 0.579444 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.286700 Acc@1: 0.577142 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.273629 Acc@1: 0.582876 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.307979 Acc@1: 0.576660 \n",
      "\tTrain Epoch: 39 \tLoss: 1.240567 Acc@1: 0.594724 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.292861 Acc@1: 0.590136 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.283883 Acc@1: 0.588245 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.300939 Acc@1: 0.582910 \n",
      "\tTrain Epoch: 40 \tLoss: 1.311134 Acc@1: 0.576372 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.280172 Acc@1: 0.591862 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.293710 Acc@1: 0.591118 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.233963 Acc@1: 0.591895 \n",
      "\tTrain Epoch: 41 \tLoss: 1.239638 Acc@1: 0.586155 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.212922 Acc@1: 0.601616 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.217567 Acc@1: 0.607566 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.250579 Acc@1: 0.601270 \n",
      "\tTrain Epoch: 42 \tLoss: 1.242781 Acc@1: 0.599710 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.353981 Acc@1: 0.575924 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.354480 Acc@1: 0.570418 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.291382 Acc@1: 0.561621 \n",
      "\tTrain Epoch: 43 \tLoss: 1.303074 Acc@1: 0.551136 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.282207 Acc@1: 0.577942 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.323066 Acc@1: 0.580365 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.298297 Acc@1: 0.568652 \n",
      "\tTrain Epoch: 44 \tLoss: 1.240474 Acc@1: 0.584646 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.286979 Acc@1: 0.586005 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.288418 Acc@1: 0.587170 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.377612 Acc@1: 0.572168 \n",
      "\tTrain Epoch: 45 \tLoss: 1.290949 Acc@1: 0.586474 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.324460 Acc@1: 0.581151 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.321374 Acc@1: 0.578184 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.292599 Acc@1: 0.583691 \n",
      "\tTrain Epoch: 46 \tLoss: 1.207738 Acc@1: 0.604467 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.241983 Acc@1: 0.599492 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.257698 Acc@1: 0.595265 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.298959 Acc@1: 0.584277 \n",
      "\tTrain Epoch: 47 \tLoss: 1.277131 Acc@1: 0.589541 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.305713 Acc@1: 0.587108 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.275639 Acc@1: 0.597182 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.222500 Acc@1: 0.597559 \n",
      "\tTrain Epoch: 48 \tLoss: 1.195533 Acc@1: 0.601687 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.227409 Acc@1: 0.602412 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.240531 Acc@1: 0.601395 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.236966 Acc@1: 0.585059 \n",
      "\tTrain Epoch: 49 \tLoss: 1.258836 Acc@1: 0.566241 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.205277 Acc@1: 0.607430 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.223504 Acc@1: 0.607345 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.298872 Acc@1: 0.606543 \n",
      "\tTrain Epoch: 50 \tLoss: 1.322454 Acc@1: 0.609685 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.241477 Acc@1: 0.617820 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.238979 Acc@1: 0.615576 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.245070 Acc@1: 0.606934 \n",
      "\tTrain Epoch: 51 \tLoss: 1.294197 Acc@1: 0.594260 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.196876 Acc@1: 0.615257 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.180083 Acc@1: 0.621877 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.227390 Acc@1: 0.617188 \n",
      "\tTrain Epoch: 52 \tLoss: 1.192110 Acc@1: 0.620070 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.196255 Acc@1: 0.625200 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.229805 Acc@1: 0.612929 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.218908 Acc@1: 0.612500 \n",
      "\tTrain Epoch: 53 \tLoss: 1.115273 Acc@1: 0.628133 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.214867 Acc@1: 0.613745 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.188423 Acc@1: 0.619538 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.201998 Acc@1: 0.613477 \n",
      "\tTrain Epoch: 54 \tLoss: 1.187932 Acc@1: 0.615497 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.191426 Acc@1: 0.619714 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.192751 Acc@1: 0.621568 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.203489 Acc@1: 0.616016 \n",
      "\tTrain Epoch: 55 \tLoss: 1.147253 Acc@1: 0.643357 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.185289 Acc@1: 0.627298 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.171575 Acc@1: 0.628441 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.205299 Acc@1: 0.619238 \n",
      "\tTrain Epoch: 56 \tLoss: 1.194019 Acc@1: 0.617532 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.152409 Acc@1: 0.632878 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.154937 Acc@1: 0.631962 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.148659 Acc@1: 0.623242 \n",
      "\tTrain Epoch: 57 \tLoss: 1.089047 Acc@1: 0.638834 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.168325 Acc@1: 0.635095 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.172256 Acc@1: 0.631891 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.229672 Acc@1: 0.600293 \n",
      "\tTrain Epoch: 58 \tLoss: 1.156718 Acc@1: 0.618474 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.176558 Acc@1: 0.625108 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.174544 Acc@1: 0.628175 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.194540 Acc@1: 0.620898 \n",
      "\tTrain Epoch: 59 \tLoss: 1.183826 Acc@1: 0.629890 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.228941 Acc@1: 0.628118 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.182089 Acc@1: 0.632263 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.152041 Acc@1: 0.630176 \n",
      "\tTrain Epoch: 60 \tLoss: 1.146875 Acc@1: 0.623010 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.111364 Acc@1: 0.645822 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.117534 Acc@1: 0.647365 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.159852 Acc@1: 0.628809 \n",
      "\tTrain Epoch: 61 \tLoss: 1.109207 Acc@1: 0.641995 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.136903 Acc@1: 0.643259 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.128734 Acc@1: 0.645263 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.131539 Acc@1: 0.633203 \n",
      "\tTrain Epoch: 62 \tLoss: 1.091304 Acc@1: 0.645544 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.095035 Acc@1: 0.652541 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.112163 Acc@1: 0.649436 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.204968 Acc@1: 0.621289 \n",
      "\tTrain Epoch: 63 \tLoss: 1.153283 Acc@1: 0.645097 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.131962 Acc@1: 0.638825 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.122282 Acc@1: 0.642621 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.156430 Acc@1: 0.627051 \n",
      "\tTrain Epoch: 64 \tLoss: 1.062528 Acc@1: 0.644178 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.179869 Acc@1: 0.639129 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.166398 Acc@1: 0.640688 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.225342 Acc@1: 0.624512 \n",
      "\tTrain Epoch: 65 \tLoss: 1.135278 Acc@1: 0.654162 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.135221 Acc@1: 0.646811 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.124159 Acc@1: 0.646357 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.203199 Acc@1: 0.627637 \n",
      "\tTrain Epoch: 66 \tLoss: 1.156518 Acc@1: 0.642029 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.106604 Acc@1: 0.648487 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.092319 Acc@1: 0.648302 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.191846 Acc@1: 0.641797 \n",
      "\tTrain Epoch: 67 \tLoss: 1.118981 Acc@1: 0.660184 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.100662 Acc@1: 0.649376 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.103244 Acc@1: 0.651311 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.167294 Acc@1: 0.635645 \n",
      "\tTrain Epoch: 68 \tLoss: 1.143113 Acc@1: 0.653981 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 1.085974 Acc@1: 0.654931 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 1.102716 Acc@1: 0.654740 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.092103 Acc@1: 0.641602 \n",
      "\tTrain Epoch: 69 \tLoss: 1.055210 Acc@1: 0.656156 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.082398 Acc@1: 0.654962 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.079457 Acc@1: 0.657621 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.125511 Acc@1: 0.643164 \n",
      "\tTrain Epoch: 70 \tLoss: 1.067776 Acc@1: 0.666500 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.075875 Acc@1: 0.666726 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.067377 Acc@1: 0.664805 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.168324 Acc@1: 0.646680 \n",
      "\tTrain Epoch: 71 \tLoss: 1.100144 Acc@1: 0.662055 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.075746 Acc@1: 0.664933 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.072164 Acc@1: 0.666804 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.142783 Acc@1: 0.641602 \n",
      "\tTrain Epoch: 72 \tLoss: 1.050819 Acc@1: 0.657948 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.055067 Acc@1: 0.666312 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.057080 Acc@1: 0.667146 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.151131 Acc@1: 0.639746 \n",
      "\tTrain Epoch: 73 \tLoss: 1.084986 Acc@1: 0.645473 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.095964 Acc@1: 0.660056 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.083997 Acc@1: 0.661447 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.138318 Acc@1: 0.651172 \n",
      "\tTrain Epoch: 74 \tLoss: 1.093455 Acc@1: 0.669557 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.057873 Acc@1: 0.671746 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.046096 Acc@1: 0.671045 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.153796 Acc@1: 0.657031 \n",
      "\tTrain Epoch: 75 \tLoss: 1.122189 Acc@1: 0.673126 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.067244 Acc@1: 0.670217 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.033804 Acc@1: 0.674227 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.090912 Acc@1: 0.648633 \n",
      "\tTrain Epoch: 76 \tLoss: 1.046472 Acc@1: 0.670500 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.019834 Acc@1: 0.674965 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.017404 Acc@1: 0.678241 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.078577 Acc@1: 0.657129 \n",
      "\tTrain Epoch: 77 \tLoss: 1.031096 Acc@1: 0.678699 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 1.012224 Acc@1: 0.679593 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 1.012746 Acc@1: 0.681421 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.095572 Acc@1: 0.670605 \n",
      "\tTrain Epoch: 78 \tLoss: 1.016682 Acc@1: 0.681951 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.050471 Acc@1: 0.681020 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.058030 Acc@1: 0.678590 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.069953 Acc@1: 0.666992 \n",
      "\tTrain Epoch: 79 \tLoss: 1.068545 Acc@1: 0.663882 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.033639 Acc@1: 0.684627 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.022763 Acc@1: 0.681722 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 1.063015 Acc@1: 0.665918 \n",
      "\tTrain Epoch: 80 \tLoss: 1.039587 Acc@1: 0.687500 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 1.005367 Acc@1: 0.693362 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 0.983059 Acc@1: 0.696575 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.072009 Acc@1: 0.675586 \n",
      "\tTrain Epoch: 81 \tLoss: 1.014877 Acc@1: 0.687820 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 1.009903 Acc@1: 0.695999 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 0.997462 Acc@1: 0.694670 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.031286 Acc@1: 0.669629 \n",
      "\tTrain Epoch: 82 \tLoss: 0.996483 Acc@1: 0.682289 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 0.999511 Acc@1: 0.690270 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 0.983893 Acc@1: 0.694125 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.136460 Acc@1: 0.661816 \n",
      "\tTrain Epoch: 83 \tLoss: 1.006556 Acc@1: 0.684263 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.098020 Acc@1: 0.673434 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.095615 Acc@1: 0.673151 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.104281 Acc@1: 0.653906 \n",
      "\tTrain Epoch: 84 \tLoss: 1.092938 Acc@1: 0.660597 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 1.088049 Acc@1: 0.671247 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 1.110153 Acc@1: 0.670559 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.091470 Acc@1: 0.657910 \n",
      "\tTrain Epoch: 85 \tLoss: 1.048856 Acc@1: 0.661616 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.058803 Acc@1: 0.675999 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.077753 Acc@1: 0.675352 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.126569 Acc@1: 0.651660 \n",
      "\tTrain Epoch: 86 \tLoss: 1.056067 Acc@1: 0.666324 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 1.044910 Acc@1: 0.678402 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 1.034646 Acc@1: 0.680484 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.104441 Acc@1: 0.672949 \n",
      "\tTrain Epoch: 87 \tLoss: 1.034092 Acc@1: 0.695761 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.029847 Acc@1: 0.688150 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.033448 Acc@1: 0.688158 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.098580 Acc@1: 0.671094 \n",
      "\tTrain Epoch: 88 \tLoss: 1.039238 Acc@1: 0.689432 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 1.036210 Acc@1: 0.687469 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 1.038296 Acc@1: 0.685907 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.094195 Acc@1: 0.667090 \n",
      "\tTrain Epoch: 89 \tLoss: 0.999962 Acc@1: 0.693054 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.016574 Acc@1: 0.687858 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 1.008570 Acc@1: 0.689256 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.055290 Acc@1: 0.666895 \n",
      "\tTrain Epoch: 90 \tLoss: 0.987273 Acc@1: 0.682294 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 1.002852 Acc@1: 0.691702 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 0.997597 Acc@1: 0.693300 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 22:38:51:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 22:38:51:INFO:{'accuracy': 0.6755859375, 'accuracy_per_epoch': [0.1962890625, 0.25908203125, 0.315625, 0.3318359375, 0.36669921875, 0.3798828125, 0.3814453125, 0.405859375, 0.39912109375, 0.4380859375, 0.430859375, 0.43125, 0.43486328125, 0.45517578125, 0.45234375, 0.474609375, 0.47783203125, 0.49501953125, 0.49140625, 0.5162109375, 0.4791015625, 0.47607421875, 0.49248046875, 0.5017578125, 0.5091796875, 0.5138671875, 0.5216796875, 0.52900390625, 0.541796875, 0.53447265625, 0.54345703125, 0.55419921875, 0.54140625, 0.54560546875, 0.56376953125, 0.5587890625, 0.55927734375, 0.57666015625, 0.58291015625, 0.59189453125, 0.60126953125, 0.56162109375, 0.56865234375, 0.57216796875, 0.58369140625, 0.58427734375, 0.59755859375, 0.58505859375, 0.60654296875, 0.60693359375, 0.6171875, 0.6125, 0.6134765625, 0.616015625, 0.61923828125, 0.6232421875, 0.60029296875, 0.6208984375, 0.63017578125, 0.62880859375, 0.633203125, 0.6212890625, 0.62705078125, 0.62451171875, 0.62763671875, 0.641796875, 0.63564453125, 0.6416015625, 0.6431640625, 0.6466796875, 0.6416015625, 0.63974609375, 0.651171875, 0.65703125, 0.6486328125, 0.65712890625, 0.67060546875, 0.6669921875, 0.66591796875, 0.6755859375, 0.66962890625, 0.66181640625, 0.65390625, 0.65791015625, 0.65166015625, 0.67294921875, 0.67109375, 0.66708984375, 0.66689453125, 0.6595703125], 'avg_time_per_epoch_str': '0:00:09', 'time_per_epoch': [11.931498, 9.04464, 8.936378, 9.029747, 9.098732, 9.102916, 9.105895, 9.030225, 9.01585, 9.081697, 9.151301, 9.002531, 9.076232, 9.063094, 9.057912, 9.096569, 9.117181, 9.074986, 9.082678, 8.94957, 9.016118, 8.960365, 9.087079, 8.998039, 9.019208, 9.067268, 8.958139, 9.026937, 9.052391, 9.062518, 9.009453, 8.978879, 9.048851, 9.057964, 8.986797, 8.992055, 8.952179, 9.067174, 8.985708, 9.001371, 9.003479, 9.017999, 8.989836, 9.015757, 8.904608, 9.052997, 9.025603, 9.023293, 8.910043, 8.978927, 8.947612, 8.942041, 9.013876, 8.948982, 8.933011, 8.93063, 8.965663, 8.910658, 9.034404, 8.88025, 8.936362, 8.878802, 8.934125, 8.860866, 8.992039, 9.067129, 8.886341, 8.916244, 8.937046, 8.899407, 8.927726, 8.964707, 8.867149, 9.017436, 8.885928, 8.891894, 8.872477, 8.942802, 8.95188, 8.952311, 9.050051, 8.931531, 8.995845, 8.907605, 8.95776, 8.906543, 9.013973, 8.995833, 8.913987, 8.895352]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.149405 Acc@1: 0.659570 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='BCRG',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "(7) We test the learning effectiveness for Private learning for Opacus-DPCR with **ABCRG model**.\n",
    "\n",
    "The experimental results indicate that under (2, 1e-5)-Differential Privacy, **ABCRG** achieves:\n",
    "Accuracy of **69.0%** and Loss of **1.04** after private training.\n",
    "Best Accuracy of **69.4%** and best Loss of **1.00** during private training.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You set sigma as 4.18.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "> You select DPCR with ABCRG...\n",
      "\tTrain Epoch: 1 \tLoss: 2.303600 Acc@1: 0.108362 (ε = 0.11, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.301182 Acc@1: 0.123689 (ε = 0.14, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 1 \tLoss: 2.270447 Acc@1: 0.149166 (ε = 0.18, δ = 1e-05) for α = 63.0\n",
      "\tTest set:Loss: 2.154024 Acc@1: 0.215918 \n",
      "\tTrain Epoch: 2 \tLoss: 2.195047 Acc@1: 0.214540 (ε = 0.19, δ = 1e-05) for α = 63.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.161597 Acc@1: 0.223706 (ε = 0.23, δ = 1e-05) for α = 58.0\n",
      "\tTrain Epoch: 2 \tLoss: 2.103574 Acc@1: 0.238220 (ε = 0.26, δ = 1e-05) for α = 53.0\n",
      "\tTest set:Loss: 2.006029 Acc@1: 0.281543 \n",
      "\tTrain Epoch: 3 \tLoss: 2.014762 Acc@1: 0.285128 (ε = 0.27, δ = 1e-05) for α = 50.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.983361 Acc@1: 0.284622 (ε = 0.30, δ = 1e-05) for α = 47.0\n",
      "\tTrain Epoch: 3 \tLoss: 1.936281 Acc@1: 0.300385 (ε = 0.32, δ = 1e-05) for α = 44.0\n",
      "\tTest set:Loss: 1.974154 Acc@1: 0.320703 \n",
      "\tTrain Epoch: 4 \tLoss: 2.000982 Acc@1: 0.310704 (ε = 0.33, δ = 1e-05) for α = 43.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.925195 Acc@1: 0.307368 (ε = 0.35, δ = 1e-05) for α = 41.0\n",
      "\tTrain Epoch: 4 \tLoss: 1.897366 Acc@1: 0.318380 (ε = 0.37, δ = 1e-05) for α = 39.0\n",
      "\tTest set:Loss: 1.819693 Acc@1: 0.340234 \n",
      "\tTrain Epoch: 5 \tLoss: 1.810081 Acc@1: 0.325381 (ε = 0.38, δ = 1e-05) for α = 38.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.800936 Acc@1: 0.347643 (ε = 0.40, δ = 1e-05) for α = 37.0\n",
      "\tTrain Epoch: 5 \tLoss: 1.786440 Acc@1: 0.358919 (ε = 0.42, δ = 1e-05) for α = 35.0\n",
      "\tTest set:Loss: 1.832758 Acc@1: 0.377148 \n",
      "\tTrain Epoch: 6 \tLoss: 1.821580 Acc@1: 0.386792 (ε = 0.43, δ = 1e-05) for α = 35.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.772142 Acc@1: 0.374582 (ε = 0.45, δ = 1e-05) for α = 34.0\n",
      "\tTrain Epoch: 6 \tLoss: 1.768870 Acc@1: 0.371669 (ε = 0.46, δ = 1e-05) for α = 33.0\n",
      "\tTest set:Loss: 1.844053 Acc@1: 0.358594 \n",
      "\tTrain Epoch: 7 \tLoss: 1.838270 Acc@1: 0.340921 (ε = 0.47, δ = 1e-05) for α = 32.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.776722 Acc@1: 0.373022 (ε = 0.49, δ = 1e-05) for α = 31.0\n",
      "\tTrain Epoch: 7 \tLoss: 1.755714 Acc@1: 0.382346 (ε = 0.50, δ = 1e-05) for α = 30.0\n",
      "\tTest set:Loss: 1.723763 Acc@1: 0.406836 \n",
      "\tTrain Epoch: 8 \tLoss: 1.700810 Acc@1: 0.407704 (ε = 0.51, δ = 1e-05) for α = 30.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.719491 Acc@1: 0.407267 (ε = 0.53, δ = 1e-05) for α = 29.0\n",
      "\tTrain Epoch: 8 \tLoss: 1.717359 Acc@1: 0.408785 (ε = 0.54, δ = 1e-05) for α = 29.0\n",
      "\tTest set:Loss: 1.726965 Acc@1: 0.406836 \n",
      "\tTrain Epoch: 9 \tLoss: 1.720755 Acc@1: 0.407333 (ε = 0.55, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.673825 Acc@1: 0.423317 (ε = 0.56, δ = 1e-05) for α = 28.0\n",
      "\tTrain Epoch: 9 \tLoss: 1.672931 Acc@1: 0.422821 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTest set:Loss: 1.595265 Acc@1: 0.447070 \n",
      "\tTrain Epoch: 10 \tLoss: 1.594286 Acc@1: 0.444995 (ε = 0.58, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.618194 Acc@1: 0.441071 (ε = 0.60, δ = 1e-05) for α = 27.0\n",
      "\tTrain Epoch: 10 \tLoss: 1.637739 Acc@1: 0.435883 (ε = 0.61, δ = 1e-05) for α = 26.0\n",
      "\tTest set:Loss: 1.654073 Acc@1: 0.436914 \n",
      "\tTrain Epoch: 11 \tLoss: 1.674637 Acc@1: 0.442011 (ε = 0.62, δ = 1e-05) for α = 26.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.675558 Acc@1: 0.438273 (ε = 0.63, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 11 \tLoss: 1.668929 Acc@1: 0.429814 (ε = 0.64, δ = 1e-05) for α = 25.0\n",
      "\tTest set:Loss: 1.640937 Acc@1: 0.421484 \n",
      "\tTrain Epoch: 12 \tLoss: 1.643680 Acc@1: 0.425863 (ε = 0.65, δ = 1e-05) for α = 25.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.661200 Acc@1: 0.426529 (ε = 0.66, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 12 \tLoss: 1.633131 Acc@1: 0.437316 (ε = 0.67, δ = 1e-05) for α = 24.0\n",
      "\tTest set:Loss: 1.602589 Acc@1: 0.452637 \n",
      "\tTrain Epoch: 13 \tLoss: 1.636074 Acc@1: 0.444556 (ε = 0.68, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.606971 Acc@1: 0.451741 (ε = 0.69, δ = 1e-05) for α = 24.0\n",
      "\tTrain Epoch: 13 \tLoss: 1.603837 Acc@1: 0.452125 (ε = 0.70, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.543208 Acc@1: 0.464941 \n",
      "\tTrain Epoch: 14 \tLoss: 1.496362 Acc@1: 0.468442 (ε = 0.71, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.558860 Acc@1: 0.469222 (ε = 0.72, δ = 1e-05) for α = 23.0\n",
      "\tTrain Epoch: 14 \tLoss: 1.571554 Acc@1: 0.465694 (ε = 0.73, δ = 1e-05) for α = 23.0\n",
      "\tTest set:Loss: 1.628977 Acc@1: 0.465820 \n",
      "\tTrain Epoch: 15 \tLoss: 1.619850 Acc@1: 0.461693 (ε = 0.74, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.537210 Acc@1: 0.475452 (ε = 0.75, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 15 \tLoss: 1.546878 Acc@1: 0.474609 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTest set:Loss: 1.468741 Acc@1: 0.483984 \n",
      "\tTrain Epoch: 16 \tLoss: 1.430063 Acc@1: 0.513747 (ε = 0.76, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.510433 Acc@1: 0.486104 (ε = 0.77, δ = 1e-05) for α = 22.0\n",
      "\tTrain Epoch: 16 \tLoss: 1.536287 Acc@1: 0.486530 (ε = 0.78, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.521542 Acc@1: 0.475293 \n",
      "\tTrain Epoch: 17 \tLoss: 1.592582 Acc@1: 0.460513 (ε = 0.79, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.561302 Acc@1: 0.478723 (ε = 0.80, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 17 \tLoss: 1.537413 Acc@1: 0.486563 (ε = 0.81, δ = 1e-05) for α = 21.0\n",
      "\tTest set:Loss: 1.454183 Acc@1: 0.491016 \n",
      "\tTrain Epoch: 18 \tLoss: 1.465946 Acc@1: 0.504791 (ε = 0.82, δ = 1e-05) for α = 21.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.491850 Acc@1: 0.491343 (ε = 0.83, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 18 \tLoss: 1.492351 Acc@1: 0.494950 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.475766 Acc@1: 0.500293 \n",
      "\tTrain Epoch: 19 \tLoss: 1.433873 Acc@1: 0.504636 (ε = 0.84, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.489766 Acc@1: 0.506522 (ε = 0.85, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 19 \tLoss: 1.471891 Acc@1: 0.511457 (ε = 0.86, δ = 1e-05) for α = 20.0\n",
      "\tTest set:Loss: 1.449303 Acc@1: 0.512793 \n",
      "\tTrain Epoch: 20 \tLoss: 1.462443 Acc@1: 0.513471 (ε = 0.87, δ = 1e-05) for α = 20.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.461538 Acc@1: 0.514037 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 20 \tLoss: 1.454885 Acc@1: 0.519825 (ε = 0.88, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.419876 Acc@1: 0.522363 \n",
      "\tTrain Epoch: 21 \tLoss: 1.384252 Acc@1: 0.531004 (ε = 0.89, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.407330 Acc@1: 0.528607 (ε = 0.90, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 21 \tLoss: 1.411822 Acc@1: 0.527759 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.461099 Acc@1: 0.504492 \n",
      "\tTrain Epoch: 22 \tLoss: 1.539510 Acc@1: 0.495709 (ε = 0.91, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.505410 Acc@1: 0.497013 (ε = 0.92, δ = 1e-05) for α = 19.0\n",
      "\tTrain Epoch: 22 \tLoss: 1.496453 Acc@1: 0.498038 (ε = 0.93, δ = 1e-05) for α = 19.0\n",
      "\tTest set:Loss: 1.458298 Acc@1: 0.505762 \n",
      "\tTrain Epoch: 23 \tLoss: 1.477771 Acc@1: 0.511707 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.500316 Acc@1: 0.514724 (ε = 0.94, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 23 \tLoss: 1.484613 Acc@1: 0.513983 (ε = 0.95, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.425309 Acc@1: 0.516504 \n",
      "\tTrain Epoch: 24 \tLoss: 1.457650 Acc@1: 0.510046 (ε = 0.96, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.423959 Acc@1: 0.518399 (ε = 0.97, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 24 \tLoss: 1.464406 Acc@1: 0.517265 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.504789 Acc@1: 0.504395 \n",
      "\tTrain Epoch: 25 \tLoss: 1.513890 Acc@1: 0.503671 (ε = 0.98, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.435417 Acc@1: 0.523446 (ε = 0.99, δ = 1e-05) for α = 18.0\n",
      "\tTrain Epoch: 25 \tLoss: 1.422863 Acc@1: 0.526754 (ε = 1.00, δ = 1e-05) for α = 18.0\n",
      "\tTest set:Loss: 1.444452 Acc@1: 0.528809 \n",
      "\tTrain Epoch: 26 \tLoss: 1.394037 Acc@1: 0.545455 (ε = 1.00, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.409392 Acc@1: 0.538875 (ε = 1.01, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 26 \tLoss: 1.412245 Acc@1: 0.542029 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.428174 Acc@1: 0.537891 \n",
      "\tTrain Epoch: 27 \tLoss: 1.448287 Acc@1: 0.539251 (ε = 1.02, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.413568 Acc@1: 0.536024 (ε = 1.03, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 27 \tLoss: 1.411607 Acc@1: 0.538453 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.406574 Acc@1: 0.533594 \n",
      "\tTrain Epoch: 28 \tLoss: 1.320832 Acc@1: 0.555893 (ε = 1.04, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.402291 Acc@1: 0.547480 (ε = 1.05, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 28 \tLoss: 1.379661 Acc@1: 0.551528 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTest set:Loss: 1.376326 Acc@1: 0.546289 \n",
      "\tTrain Epoch: 29 \tLoss: 1.457114 Acc@1: 0.547264 (ε = 1.06, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.347328 Acc@1: 0.565412 (ε = 1.07, δ = 1e-05) for α = 17.0\n",
      "\tTrain Epoch: 29 \tLoss: 1.355613 Acc@1: 0.564831 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.374971 Acc@1: 0.554688 \n",
      "\tTrain Epoch: 30 \tLoss: 1.319306 Acc@1: 0.582866 (ε = 1.08, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.369914 Acc@1: 0.563654 (ε = 1.09, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 30 \tLoss: 1.340004 Acc@1: 0.568382 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.320055 Acc@1: 0.562402 \n",
      "\tTrain Epoch: 31 \tLoss: 1.299186 Acc@1: 0.584337 (ε = 1.10, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.334756 Acc@1: 0.573548 (ε = 1.11, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 31 \tLoss: 1.325372 Acc@1: 0.572927 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.374713 Acc@1: 0.559473 \n",
      "\tTrain Epoch: 32 \tLoss: 1.293902 Acc@1: 0.584331 (ε = 1.12, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.334099 Acc@1: 0.571281 (ε = 1.13, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 32 \tLoss: 1.339988 Acc@1: 0.569724 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.354965 Acc@1: 0.569922 \n",
      "\tTrain Epoch: 33 \tLoss: 1.268568 Acc@1: 0.598446 (ε = 1.14, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.288985 Acc@1: 0.575860 (ε = 1.15, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 33 \tLoss: 1.296472 Acc@1: 0.577635 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTest set:Loss: 1.320186 Acc@1: 0.572559 \n",
      "\tTrain Epoch: 34 \tLoss: 1.276388 Acc@1: 0.578004 (ε = 1.16, δ = 1e-05) for α = 16.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.308832 Acc@1: 0.586963 (ε = 1.17, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 34 \tLoss: 1.301493 Acc@1: 0.586079 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.290805 Acc@1: 0.587305 \n",
      "\tTrain Epoch: 35 \tLoss: 1.269284 Acc@1: 0.598236 (ε = 1.18, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.335316 Acc@1: 0.583214 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 35 \tLoss: 1.310041 Acc@1: 0.587267 (ε = 1.19, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.319950 Acc@1: 0.560937 \n",
      "\tTrain Epoch: 36 \tLoss: 1.290077 Acc@1: 0.559454 (ε = 1.20, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.263618 Acc@1: 0.588370 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 36 \tLoss: 1.265247 Acc@1: 0.594644 (ε = 1.21, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.313808 Acc@1: 0.582031 \n",
      "\tTrain Epoch: 37 \tLoss: 1.298204 Acc@1: 0.603380 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.269141 Acc@1: 0.596925 (ε = 1.22, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 37 \tLoss: 1.312653 Acc@1: 0.588344 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.319050 Acc@1: 0.576172 \n",
      "\tTrain Epoch: 38 \tLoss: 1.229225 Acc@1: 0.602781 (ε = 1.23, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.237642 Acc@1: 0.599214 (ε = 1.24, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 38 \tLoss: 1.237165 Acc@1: 0.602286 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTest set:Loss: 1.300845 Acc@1: 0.600293 \n",
      "\tTrain Epoch: 39 \tLoss: 1.195038 Acc@1: 0.621583 (ε = 1.25, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.264569 Acc@1: 0.609952 (ε = 1.26, δ = 1e-05) for α = 15.0\n",
      "\tTrain Epoch: 39 \tLoss: 1.251017 Acc@1: 0.611749 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.267940 Acc@1: 0.588379 \n",
      "\tTrain Epoch: 40 \tLoss: 1.227460 Acc@1: 0.586258 (ε = 1.27, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.228895 Acc@1: 0.602049 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 40 \tLoss: 1.231939 Acc@1: 0.606194 (ε = 1.28, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.244138 Acc@1: 0.612598 \n",
      "\tTrain Epoch: 41 \tLoss: 1.236382 Acc@1: 0.631972 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.178066 Acc@1: 0.626463 (ε = 1.29, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 41 \tLoss: 1.188094 Acc@1: 0.627803 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.275192 Acc@1: 0.608594 \n",
      "\tTrain Epoch: 42 \tLoss: 1.268462 Acc@1: 0.598742 (ε = 1.30, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.287128 Acc@1: 0.600865 (ε = 1.31, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 42 \tLoss: 1.289614 Acc@1: 0.595105 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.309034 Acc@1: 0.581445 \n",
      "\tTrain Epoch: 43 \tLoss: 1.355563 Acc@1: 0.569215 (ε = 1.32, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.277388 Acc@1: 0.594454 (ε = 1.33, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 43 \tLoss: 1.271395 Acc@1: 0.597342 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.319076 Acc@1: 0.576270 \n",
      "\tTrain Epoch: 44 \tLoss: 1.295611 Acc@1: 0.590551 (ε = 1.34, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.288951 Acc@1: 0.593289 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 44 \tLoss: 1.275102 Acc@1: 0.598425 (ε = 1.35, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.214627 Acc@1: 0.604199 \n",
      "\tTrain Epoch: 45 \tLoss: 1.151300 Acc@1: 0.627259 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.222978 Acc@1: 0.612782 (ε = 1.36, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 45 \tLoss: 1.218000 Acc@1: 0.613023 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTest set:Loss: 1.316307 Acc@1: 0.593848 \n",
      "\tTrain Epoch: 46 \tLoss: 1.222429 Acc@1: 0.615881 (ε = 1.37, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.275101 Acc@1: 0.608446 (ε = 1.38, δ = 1e-05) for α = 14.0\n",
      "\tTrain Epoch: 46 \tLoss: 1.263787 Acc@1: 0.608993 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.238888 Acc@1: 0.613477 \n",
      "\tTrain Epoch: 47 \tLoss: 1.201242 Acc@1: 0.611248 (ε = 1.39, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.183509 Acc@1: 0.626391 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 47 \tLoss: 1.196000 Acc@1: 0.623852 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.252434 Acc@1: 0.607324 \n",
      "\tTrain Epoch: 48 \tLoss: 1.193649 Acc@1: 0.627976 (ε = 1.40, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.213670 Acc@1: 0.624894 (ε = 1.41, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 48 \tLoss: 1.193862 Acc@1: 0.627377 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.234529 Acc@1: 0.604883 \n",
      "\tTrain Epoch: 49 \tLoss: 1.214442 Acc@1: 0.610893 (ε = 1.42, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.220880 Acc@1: 0.626521 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 49 \tLoss: 1.214190 Acc@1: 0.625149 (ε = 1.43, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.215458 Acc@1: 0.620898 \n",
      "\tTrain Epoch: 50 \tLoss: 1.192084 Acc@1: 0.638257 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.180438 Acc@1: 0.635677 (ε = 1.44, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 50 \tLoss: 1.197110 Acc@1: 0.631210 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.219137 Acc@1: 0.624512 \n",
      "\tTrain Epoch: 51 \tLoss: 1.256830 Acc@1: 0.606136 (ε = 1.45, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.191020 Acc@1: 0.627079 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 51 \tLoss: 1.165634 Acc@1: 0.634420 (ε = 1.46, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.194695 Acc@1: 0.634277 \n",
      "\tTrain Epoch: 52 \tLoss: 1.133651 Acc@1: 0.658512 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.163433 Acc@1: 0.649407 (ε = 1.47, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 52 \tLoss: 1.196438 Acc@1: 0.638825 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.194135 Acc@1: 0.614941 \n",
      "\tTrain Epoch: 53 \tLoss: 1.112142 Acc@1: 0.635294 (ε = 1.48, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.178275 Acc@1: 0.624461 (ε = 1.49, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 53 \tLoss: 1.155099 Acc@1: 0.632615 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.198414 Acc@1: 0.621191 \n",
      "\tTrain Epoch: 54 \tLoss: 1.199028 Acc@1: 0.609649 (ε = 1.50, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.181979 Acc@1: 0.633582 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 54 \tLoss: 1.162360 Acc@1: 0.637166 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTest set:Loss: 1.207471 Acc@1: 0.630469 \n",
      "\tTrain Epoch: 55 \tLoss: 1.117079 Acc@1: 0.644356 (ε = 1.51, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.179211 Acc@1: 0.644760 (ε = 1.52, δ = 1e-05) for α = 13.0\n",
      "\tTrain Epoch: 55 \tLoss: 1.183014 Acc@1: 0.643309 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.229730 Acc@1: 0.620801 \n",
      "\tTrain Epoch: 56 \tLoss: 1.113287 Acc@1: 0.654750 (ε = 1.53, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.163957 Acc@1: 0.641379 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 56 \tLoss: 1.143724 Acc@1: 0.645317 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.151223 Acc@1: 0.638281 \n",
      "\tTrain Epoch: 57 \tLoss: 1.108118 Acc@1: 0.661067 (ε = 1.54, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.106375 Acc@1: 0.656493 (ε = 1.55, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 57 \tLoss: 1.106958 Acc@1: 0.656957 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.200022 Acc@1: 0.629785 \n",
      "\tTrain Epoch: 58 \tLoss: 1.124538 Acc@1: 0.661145 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.155853 Acc@1: 0.649398 (ε = 1.56, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 58 \tLoss: 1.138042 Acc@1: 0.650815 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.143461 Acc@1: 0.638770 \n",
      "\tTrain Epoch: 59 \tLoss: 1.112312 Acc@1: 0.650953 (ε = 1.57, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.098268 Acc@1: 0.662525 (ε = 1.58, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 59 \tLoss: 1.080751 Acc@1: 0.667225 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.112739 Acc@1: 0.659180 \n",
      "\tTrain Epoch: 60 \tLoss: 1.073678 Acc@1: 0.671803 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.102314 Acc@1: 0.662440 (ε = 1.59, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 60 \tLoss: 1.098509 Acc@1: 0.661502 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.109512 Acc@1: 0.646387 \n",
      "\tTrain Epoch: 61 \tLoss: 1.070301 Acc@1: 0.660367 (ε = 1.60, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.076418 Acc@1: 0.663574 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 61 \tLoss: 1.074324 Acc@1: 0.665184 (ε = 1.61, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.141140 Acc@1: 0.647754 \n",
      "\tTrain Epoch: 62 \tLoss: 1.110123 Acc@1: 0.657393 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.086220 Acc@1: 0.672510 (ε = 1.62, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 62 \tLoss: 1.120205 Acc@1: 0.664111 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.169240 Acc@1: 0.626172 \n",
      "\tTrain Epoch: 63 \tLoss: 1.101004 Acc@1: 0.659532 (ε = 1.63, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.121126 Acc@1: 0.648977 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 63 \tLoss: 1.126826 Acc@1: 0.651872 (ε = 1.64, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.127750 Acc@1: 0.646387 \n",
      "\tTrain Epoch: 64 \tLoss: 1.071649 Acc@1: 0.651174 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.109918 Acc@1: 0.657792 (ε = 1.65, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 64 \tLoss: 1.116200 Acc@1: 0.658287 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.134657 Acc@1: 0.648438 \n",
      "\tTrain Epoch: 65 \tLoss: 1.037323 Acc@1: 0.680884 (ε = 1.66, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.072662 Acc@1: 0.670508 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 65 \tLoss: 1.087373 Acc@1: 0.667217 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.159026 Acc@1: 0.645801 \n",
      "\tTrain Epoch: 66 \tLoss: 1.129928 Acc@1: 0.642029 (ε = 1.67, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.102423 Acc@1: 0.653055 (ε = 1.68, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 66 \tLoss: 1.087299 Acc@1: 0.659664 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.126246 Acc@1: 0.651465 \n",
      "\tTrain Epoch: 67 \tLoss: 1.037958 Acc@1: 0.682190 (ε = 1.69, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.068589 Acc@1: 0.668109 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 67 \tLoss: 1.084025 Acc@1: 0.668565 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTest set:Loss: 1.120646 Acc@1: 0.643848 \n",
      "\tTrain Epoch: 68 \tLoss: 1.093513 Acc@1: 0.652979 (ε = 1.70, δ = 1e-05) for α = 12.0\n",
      "\tTrain Epoch: 68 \tLoss: 1.060107 Acc@1: 0.665251 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 68 \tLoss: 1.087154 Acc@1: 0.662443 (ε = 1.71, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.062611 Acc@1: 0.657324 \n",
      "\tTrain Epoch: 69 \tLoss: 1.023446 Acc@1: 0.672673 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.028105 Acc@1: 0.676067 (ε = 1.72, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 69 \tLoss: 1.034428 Acc@1: 0.679808 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.144454 Acc@1: 0.648145 \n",
      "\tTrain Epoch: 70 \tLoss: 1.097213 Acc@1: 0.667501 (ε = 1.73, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.080230 Acc@1: 0.675999 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 70 \tLoss: 1.044371 Acc@1: 0.681717 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.061672 Acc@1: 0.671191 \n",
      "\tTrain Epoch: 71 \tLoss: 0.985117 Acc@1: 0.687747 (ε = 1.74, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.039094 Acc@1: 0.685117 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 71 \tLoss: 1.029598 Acc@1: 0.686554 (ε = 1.75, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.113216 Acc@1: 0.662207 \n",
      "\tTrain Epoch: 72 \tLoss: 1.027420 Acc@1: 0.706740 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.040390 Acc@1: 0.690382 (ε = 1.76, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 72 \tLoss: 1.037280 Acc@1: 0.686356 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.092270 Acc@1: 0.672852 \n",
      "\tTrain Epoch: 73 \tLoss: 0.948912 Acc@1: 0.684639 (ε = 1.77, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.058105 Acc@1: 0.677995 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 73 \tLoss: 1.061742 Acc@1: 0.671042 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.045820 Acc@1: 0.676270 \n",
      "\tTrain Epoch: 74 \tLoss: 1.018154 Acc@1: 0.699904 (ε = 1.78, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.038600 Acc@1: 0.682513 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 74 \tLoss: 1.027877 Acc@1: 0.684272 (ε = 1.79, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.085389 Acc@1: 0.673926 \n",
      "\tTrain Epoch: 75 \tLoss: 1.023689 Acc@1: 0.699133 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.010912 Acc@1: 0.693009 (ε = 1.80, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 75 \tLoss: 1.002208 Acc@1: 0.695228 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.039578 Acc@1: 0.679688 \n",
      "\tTrain Epoch: 76 \tLoss: 1.046256 Acc@1: 0.693000 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.031881 Acc@1: 0.690700 (ε = 1.81, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 76 \tLoss: 1.009828 Acc@1: 0.692320 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTest set:Loss: 1.065286 Acc@1: 0.678320 \n",
      "\tTrain Epoch: 77 \tLoss: 1.070774 Acc@1: 0.682257 (ε = 1.82, δ = 1e-05) for α = 10.9\n",
      "\tTrain Epoch: 77 \tLoss: 1.004690 Acc@1: 0.696390 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 77 \tLoss: 0.987036 Acc@1: 0.699183 (ε = 1.83, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.090945 Acc@1: 0.678125 \n",
      "\tTrain Epoch: 78 \tLoss: 1.012978 Acc@1: 0.695122 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.030992 Acc@1: 0.697839 (ε = 1.84, δ = 1e-05) for α = 10.8\n",
      "\tTrain Epoch: 78 \tLoss: 1.020333 Acc@1: 0.696201 (ε = 1.85, δ = 1e-05) for α = 10.8\n",
      "\tTest set:Loss: 1.056322 Acc@1: 0.682129 \n",
      "\tTrain Epoch: 79 \tLoss: 1.019257 Acc@1: 0.687961 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.037370 Acc@1: 0.693855 (ε = 1.85, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 79 \tLoss: 1.017089 Acc@1: 0.695849 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTest set:Loss: 1.053631 Acc@1: 0.682422 \n",
      "\tTrain Epoch: 80 \tLoss: 1.040774 Acc@1: 0.690500 (ε = 1.86, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 0.990355 Acc@1: 0.701651 (ε = 1.87, δ = 1e-05) for α = 10.7\n",
      "\tTrain Epoch: 80 \tLoss: 0.968360 Acc@1: 0.703794 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 1.009845 Acc@1: 0.691895 \n",
      "\tTrain Epoch: 81 \tLoss: 0.910151 Acc@1: 0.710850 (ε = 1.87, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 0.961632 Acc@1: 0.710586 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 81 \tLoss: 0.965026 Acc@1: 0.707344 (ε = 1.88, δ = 1e-05) for α = 10.6\n",
      "\tTest set:Loss: 0.996554 Acc@1: 0.694434 \n",
      "\tTrain Epoch: 82 \tLoss: 0.919389 Acc@1: 0.703009 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 0.951829 Acc@1: 0.709376 (ε = 1.89, δ = 1e-05) for α = 10.6\n",
      "\tTrain Epoch: 82 \tLoss: 0.960487 Acc@1: 0.707799 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.085930 Acc@1: 0.681250 \n",
      "\tTrain Epoch: 83 \tLoss: 0.969144 Acc@1: 0.700697 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.052429 Acc@1: 0.687924 (ε = 1.90, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 83 \tLoss: 1.065470 Acc@1: 0.686738 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTest set:Loss: 1.103463 Acc@1: 0.675488 \n",
      "\tTrain Epoch: 84 \tLoss: 1.037154 Acc@1: 0.681335 (ε = 1.91, δ = 1e-05) for α = 10.5\n",
      "\tTrain Epoch: 84 \tLoss: 1.081050 Acc@1: 0.681764 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 84 \tLoss: 1.071609 Acc@1: 0.680438 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.137707 Acc@1: 0.674414 \n",
      "\tTrain Epoch: 85 \tLoss: 1.077466 Acc@1: 0.689899 (ε = 1.92, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.029308 Acc@1: 0.692236 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 85 \tLoss: 1.022237 Acc@1: 0.693214 (ε = 1.93, δ = 1e-05) for α = 10.4\n",
      "\tTest set:Loss: 1.110293 Acc@1: 0.671484 \n",
      "\tTrain Epoch: 86 \tLoss: 1.067713 Acc@1: 0.682752 (ε = 1.94, δ = 1e-05) for α = 10.4\n",
      "\tTrain Epoch: 86 \tLoss: 1.017689 Acc@1: 0.693922 (ε = 1.94, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 86 \tLoss: 1.011480 Acc@1: 0.691507 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.044294 Acc@1: 0.685059 \n",
      "\tTrain Epoch: 87 \tLoss: 0.993115 Acc@1: 0.715212 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.017889 Acc@1: 0.696611 (ε = 1.95, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 87 \tLoss: 1.022399 Acc@1: 0.698751 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTest set:Loss: 1.078291 Acc@1: 0.678418 \n",
      "\tTrain Epoch: 88 \tLoss: 1.036992 Acc@1: 0.694047 (ε = 1.96, δ = 1e-05) for α = 10.3\n",
      "\tTrain Epoch: 88 \tLoss: 1.021782 Acc@1: 0.695510 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 88 \tLoss: 1.009550 Acc@1: 0.700042 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.055078 Acc@1: 0.690723 \n",
      "\tTrain Epoch: 89 \tLoss: 0.970665 Acc@1: 0.704801 (ε = 1.97, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 0.992037 Acc@1: 0.700192 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 89 \tLoss: 0.983129 Acc@1: 0.703306 (ε = 1.98, δ = 1e-05) for α = 10.2\n",
      "\tTest set:Loss: 1.065407 Acc@1: 0.690430 \n",
      "\tTrain Epoch: 90 \tLoss: 1.024266 Acc@1: 0.688778 (ε = 1.99, δ = 1e-05) for α = 10.2\n",
      "\tTrain Epoch: 90 \tLoss: 0.984097 Acc@1: 0.711504 (ε = 1.99, δ = 1e-05) for α = 10.1\n",
      "\tTrain Epoch: 90 \tLoss: 0.964447 Acc@1: 0.713226 (ε = 2.00, δ = 1e-05) for α = 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/25/2024 23:05:04:INFO:\n",
      "Note:\n",
      "- 'total_time' includes the data loading time, training time and testing time.\n",
      "- 'time_per_epoch' measures the training time only.\n",
      "\n",
      "01/25/2024 23:05:04:INFO:{'accuracy': 0.69443359375, 'accuracy_per_epoch': [0.21591796875, 0.28154296875, 0.320703125, 0.340234375, 0.3771484375, 0.35859375, 0.4068359375, 0.4068359375, 0.4470703125, 0.4369140625, 0.421484375, 0.45263671875, 0.46494140625, 0.4658203125, 0.483984375, 0.47529296875, 0.491015625, 0.50029296875, 0.51279296875, 0.52236328125, 0.5044921875, 0.50576171875, 0.51650390625, 0.50439453125, 0.52880859375, 0.537890625, 0.53359375, 0.5462890625, 0.5546875, 0.56240234375, 0.55947265625, 0.569921875, 0.57255859375, 0.5873046875, 0.5609375, 0.58203125, 0.576171875, 0.60029296875, 0.58837890625, 0.61259765625, 0.60859375, 0.5814453125, 0.57626953125, 0.60419921875, 0.59384765625, 0.6134765625, 0.60732421875, 0.6048828125, 0.6208984375, 0.62451171875, 0.63427734375, 0.61494140625, 0.62119140625, 0.63046875, 0.62080078125, 0.63828125, 0.62978515625, 0.63876953125, 0.6591796875, 0.64638671875, 0.64775390625, 0.626171875, 0.64638671875, 0.6484375, 0.64580078125, 0.65146484375, 0.64384765625, 0.65732421875, 0.64814453125, 0.67119140625, 0.66220703125, 0.6728515625, 0.67626953125, 0.67392578125, 0.6796875, 0.6783203125, 0.678125, 0.68212890625, 0.682421875, 0.69189453125, 0.69443359375, 0.68125, 0.67548828125, 0.6744140625, 0.671484375, 0.68505859375, 0.67841796875, 0.69072265625, 0.6904296875, 0.690234375], 'avg_time_per_epoch_str': '0:00:09', 'time_per_epoch': [11.872462, 9.025603, 8.858125, 9.012971, 8.933104, 9.033061, 9.017027, 8.959536, 9.024273, 9.087106, 9.03532, 9.053003, 9.032044, 8.977783, 8.877059, 9.049386, 9.122544, 9.001731, 8.976256, 8.987567, 8.993145, 8.9204, 8.993632, 8.89973, 9.054512, 9.070506, 8.946394, 8.8009, 8.939919, 9.005175, 8.926463, 9.011021, 8.929681, 8.978752, 9.009148, 8.944392, 8.942761, 8.960647, 8.921448, 8.945627, 8.965737, 9.032994, 8.988903, 8.960123, 8.913989, 8.973262, 8.998096, 9.066175, 8.983101, 8.849094, 9.312499, 9.171551, 9.983411, 9.202981, 9.148714, 9.240427, 9.320182, 9.123297, 8.93768, 8.969847, 8.96908, 8.88677, 8.988996, 8.969981, 8.886501, 8.990749, 8.957756, 9.071439, 8.98733, 8.957681, 8.984125, 8.937767, 8.877894, 9.03589, 8.839299, 8.79976, 8.932625, 8.978946, 8.964238, 8.957756, 9.025482, 8.991397, 9.051407, 8.885172, 8.990609, 8.900214, 8.963013, 8.956498, 8.902112, 8.958257]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.042563 Acc@1: 0.690234 \n"
     ]
    }
   ],
   "source": [
    "main(dpcr_model='ABCRG',sigma=4.18)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}